{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Week 2 Exercise: Steering Language Models\n\nIn this exercise, you'll gain hands-on experience with:\n- Loading and examining transformer architecture\n- Extracting and visualizing activation vectors\n- Creating steering vectors from contrastive pairs\n- Applying steering to control model behavior\n- Using Neuronpedia to find concept features"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch numpy matplotlib einops circuitsvis -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from einops import rearrange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Examining a Transformer\n",
    "\n",
    "Let's load GPT-2 and explore its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 small\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = model.to(device)\n",
    "model.eval()  # Evaluation mode\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of layers: {model.config.n_layer}\")\n",
    "print(f\"Hidden size: {model.config.n_embd}\")\n",
    "print(f\"Number of attention heads: {model.config.n_head}\")\n",
    "print(f\"Vocabulary size: {model.config.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Architecture Components\n",
    "\n",
    "Let's look at the main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(\"=\"*80)\n",
    "for name, module in model.named_modules():\n",
    "    if len(list(module.children())) == 0:  # Leaf modules only\n",
    "        print(f\"{name}: {module.__class__.__name__}\")\n",
    "        if name.count('.') <= 2:  # Don't go too deep\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key components:\n",
    "- `transformer.wte`: Token embeddings (encoder)\n",
    "- `transformer.h`: Transformer layers (attention + MLP)\n",
    "- `lm_head`: Output layer (decoder)\n",
    "\n",
    "Each transformer block has:\n",
    "- Attention (multihead)\n",
    "- MLP (feedforward)\n",
    "- Layer normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extracting Activation Vectors\n",
    "\n",
    "Let's extract activations at different layers to see internal representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(text, layer_idx=-1):\n",
    "    \"\"\"\n",
    "    Extract activation vectors at a specific layer.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        layer_idx: Which layer to extract from (-1 = last layer)\n",
    "    \n",
    "    Returns:\n",
    "        activations: [num_tokens, hidden_size] tensor\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # output_hidden_states=True gives us all layer activations\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # hidden_states is a tuple of (num_layers+1) tensors\n",
    "        # Each is [batch_size, seq_len, hidden_size]\n",
    "        hidden_states = outputs.hidden_states\n",
    "        \n",
    "        # Extract the desired layer\n",
    "        activations = hidden_states[layer_idx][0]  # Remove batch dimension\n",
    "    \n",
    "    return activations.cpu()\n",
    "\n",
    "# Test it\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "\n",
    "# Get activations from last layer\n",
    "activations = get_activations(text, layer_idx=-1)\n",
    "print(f\"\\nActivation shape: {activations.shape}\")\n",
    "print(f\"  {activations.shape[0]} tokens \u00d7 {activations.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Activations Across Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer_activations(text, token_idx=-1):\n",
    "    \"\"\"\n",
    "    Show how activation magnitudes change across layers for a specific token.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    # Extract activation norms at each layer\n",
    "    norms = []\n",
    "    for layer_activations in hidden_states:\n",
    "        # Get the specific token's activation\n",
    "        token_activation = layer_activations[0, token_idx, :]\n",
    "        # Compute L2 norm\n",
    "        norms.append(token_activation.norm().item())\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(norms, marker='o')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Activation Magnitude (L2 norm)')\n",
    "    plt.title(f'Activation magnitude across layers for token: \"{tokenizer.tokenize(text)[token_idx]}\"')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize\n",
    "text = \"The cat sat on the mat\"\n",
    "visualize_layer_activations(text, token_idx=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Compare Activation Patterns\n",
    "\n",
    "Extract activations for similar vs. dissimilar words and compute their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return (v1 @ v2) / (v1.norm() * v2.norm())\n",
    "\n",
    "# Compare \"cat\" vs \"dog\" vs \"democracy\"\n",
    "words = [\"The cat\", \"The dog\", \"The democracy\"]\n",
    "activations_list = []\n",
    "\n",
    "for word in words:\n",
    "    act = get_activations(word, layer_idx=-1)\n",
    "    # Get the last token's activation\n",
    "    activations_list.append(act[-1])\n",
    "\n",
    "# Compute pairwise similarities\n",
    "print(\"Cosine Similarities:\")\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i < j:\n",
    "            sim = cosine_similarity(activations_list[i], activations_list[j])\n",
    "            print(f\"  {word1} \u2194 {word2}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are \"cat\" and \"dog\" more similar to each other than to \"democracy\"? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Extracting Steering Vectors\n",
    "\n",
    "Now let's create steering vectors using contrastive pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Create Your Own Steering Vector\n",
    "\n",
    "Design contrastive pairs for a concept relevant to your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Applying Steering Vectors\n",
    "\n",
    "Now let's use our steering vector to modify model behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Vary Steering Strength\n",
    "\n",
    "Test different values of alpha to see how steering strength affects output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Compare Layers\n",
    "\n",
    "Which layer is best for steering? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Part 3: Extracting Steering Vectors\n\nNow let's create steering vectors using contrastive pairs."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which layers produce the strongest steering effects? Why might middle or late layers work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Introduction to Neuronpedia\n",
    "\n",
    "Neuronpedia provides pre-computed SAE features. Let's explore how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Neuronpedia Exploration\n",
    "\n",
    "1. **Visit**: Go to [neuronpedia.org](https://www.neuronpedia.org/)\n",
    "\n",
    "2. **Select Model**: Choose GPT-2 small or another model\n",
    "\n",
    "3. **Search Features**: Use the search bar to find concepts\n",
    "   - Example: \"positive sentiment\", \"medical\", \"legal\"\n",
    "\n",
    "4. **Examine Features**: For each feature, you can see:\n",
    "   - Examples of text that maximally activate it\n",
    "   - Which tokens trigger it\n",
    "   - Layer and feature index\n",
    "\n",
    "5. **Export Vectors**: Some versions allow downloading feature vectors\n",
    "\n",
    "### Exercise 6.1: Neuronpedia Exploration\n",
    "\n",
    "Visit Neuronpedia and:\n",
    "1. Search for features related to your concept\n",
    "2. Record 3-5 relevant features (layer, index, description)\n",
    "3. Note what kinds of examples activate each feature\n",
    "4. Compare to your contrastive steering vectors: do they capture similar patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a placeholder - actual SAE usage requires loading trained dictionaries\n",
    "# For your project, you may:\n",
    "# 1. Download feature vectors from Neuronpedia\n",
    "# 2. Load pre-trained SAEs\n",
    "# 3. Train your own SAE (advanced)\n",
    "\n",
    "print(\"SAE features would be used similarly to steering vectors:\")\n",
    "print(\"1. Load/download feature vector from Neuronpedia\")\n",
    "print(\"2. Apply it using generate_with_steering()\")\n",
    "print(\"3. Compare results with contrastive steering vectors\")\n",
    "print(\"\\nFor this week's assignment, focus on contrastive extraction.\")\n",
    "print(\"SAE features provide an alternative that you can explore and compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Putting It All Together\n",
    "\n",
    "Complete project workflow for your concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for your project assignment\n",
    "\n",
    "# 1. Define your concept\n",
    "MY_CONCEPT = \"[Your concept here]\"\n",
    "\n",
    "# 2. Create contrastive pairs\n",
    "positive_examples = [\n",
    "    # Add 10-20 examples with your concept\n",
    "]\n",
    "\n",
    "negative_examples = [\n",
    "    # Add 10-20 examples without your concept\n",
    "]\n",
    "\n",
    "# 3. Extract steering vectors at multiple layers\n",
    "layer_vectors = {}\n",
    "for layer in [0, 3, 6, 9, 11]:\n",
    "    layer_vectors[layer] = extract_steering_vector(\n",
    "        positive_examples, \n",
    "        negative_examples, \n",
    "        layer_idx=layer\n",
    "    )\n",
    "\n",
    "# 4. Test steering on examples\n",
    "test_prompts = [\n",
    "    # Add test cases\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    # Baseline\n",
    "    baseline = generate_with_steering(\n",
    "        prompt, torch.zeros_like(layer_vectors[6]), 6, alpha=0.0\n",
    "    )\n",
    "    print(f\"  Baseline: {baseline}\")\n",
    "    \n",
    "    # Positive steering\n",
    "    positive = generate_with_steering(\n",
    "        prompt, layer_vectors[6], 6, alpha=2.0\n",
    "    )\n",
    "    print(f\"  Positive: {positive}\")\n",
    "    \n",
    "    # Negative steering\n",
    "    negative = generate_with_steering(\n",
    "        prompt, layer_vectors[6], 6, alpha=-2.0\n",
    "    )\n",
    "    print(f\"  Negative: {negative}\")\n",
    "\n",
    "# 5. Analyze and document results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For your assignment:\n",
    "1. Create comprehensive contrastive datasets for your concept\n",
    "2. Extract and analyze steering vectors across layers\n",
    "3. Demonstrate successful steering on diverse examples\n",
    "4. Explore Neuronpedia for related features\n",
    "5. Document your findings and insights\n",
    "\n",
    "Save your steering vectors - you'll use them in future weeks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}