{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 5 Exercise: Circuits and Mechanistic Analysis\n",
        "\n",
        "In this exercise, you'll gain hands-on experience with:\n",
        "- Implementing path patching to trace information flow\n",
        "- Finding and analyzing induction circuits (K-composition)\n",
        "- Analyzing binding circuits (Q-composition)\n",
        "- Testing token vs concept induction mechanisms\n",
        "- Automated circuit discovery methods\n",
        "- Circuit minimality and faithfulness testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers torch numpy matplotlib einops -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from einops import rearrange\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load GPT-2 small\n",
        "model_name = \"gpt2\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\nModel: {model_name}\")\n",
        "print(f\"Number of layers: {model.config.n_layer}\")\n",
        "print(f\"Number of heads per layer: {model.config.n_head}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Path Patching Implementation\n",
        "\n",
        "Path patching lets us trace information flow from one component to another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_attention_output(model, input_ids, layer_idx, head_idx):\n",
        "    \"\"\"\n",
        "    Extract the output of a specific attention head.\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model\n",
        "        input_ids: Input token IDs [batch_size, seq_len]\n",
        "        layer_idx: Which layer\n",
        "        head_idx: Which head in that layer\n",
        "    \n",
        "    Returns:\n",
        "        head_output: [batch_size, seq_len, head_dim] tensor\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, output_attentions=True, output_hidden_states=True)\n",
        "        \n",
        "        # Get attention weights for the layer\n",
        "        # Shape: [batch_size, num_heads, seq_len, seq_len]\n",
        "        attention_weights = outputs.attentions[layer_idx]\n",
        "        \n",
        "        # Get hidden states at this layer (input to attention)\n",
        "        hidden_states = outputs.hidden_states[layer_idx]\n",
        "        \n",
        "        # Get the specific head's attention pattern\n",
        "        head_attention = attention_weights[:, head_idx, :, :]  # [batch, seq_len, seq_len]\n",
        "        \n",
        "        # Compute values (simplified - actual implementation is more complex)\n",
        "        # This is a simplified version for educational purposes\n",
        "        layer = model.transformer.h[layer_idx]\n",
        "        \n",
        "        # Project hidden states to get values\n",
        "        qkv = layer.attn.c_attn(hidden_states)\n",
        "        qkv = qkv.split(model.config.n_embd, dim=2)\n",
        "        values = qkv[2]  # [batch, seq_len, n_embd]\n",
        "        \n",
        "        # Reshape to separate heads\n",
        "        batch_size, seq_len, _ = values.shape\n",
        "        head_dim = model.config.n_embd // model.config.n_head\n",
        "        values = values.view(batch_size, seq_len, model.config.n_head, head_dim)\n",
        "        \n",
        "        # Get this head's values\n",
        "        head_values = values[:, :, head_idx, :]  # [batch, seq_len, head_dim]\n",
        "        \n",
        "        # Apply attention: output = attention_weights @ values\n",
        "        head_output = torch.bmm(head_attention, head_values)  # [batch, seq_len, head_dim]\n",
        "        \n",
        "    return head_output\n",
        "\n",
        "\n",
        "def path_patch(model, clean_input, corrupted_input, \n",
        "               source_layer, source_head, \n",
        "               target_layer, target_head,\n",
        "               composition_type='K'):\n",
        "    \"\"\"\n",
        "    Perform path patching from source head to target head.\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model\n",
        "        clean_input: Clean input token IDs\n",
        "        corrupted_input: Corrupted input token IDs\n",
        "        source_layer: Source attention layer\n",
        "        source_head: Source attention head\n",
        "        target_layer: Target attention layer\n",
        "        target_head: Target attention head\n",
        "        composition_type: 'Q', 'K', or 'V' for query/key/value composition\n",
        "    \n",
        "    Returns:\n",
        "        effect: The causal effect of this path\n",
        "    \"\"\"\n",
        "    # This is a simplified implementation for educational purposes\n",
        "    # A full implementation would require custom forward hooks\n",
        "    \n",
        "    # Get source head outputs for clean and corrupted\n",
        "    clean_source_output = get_attention_output(model, clean_input, source_layer, source_head)\n",
        "    corrupted_source_output = get_attention_output(model, corrupted_input, source_layer, source_head)\n",
        "    \n",
        "    # Compute the difference\n",
        "    source_diff = clean_source_output - corrupted_source_output\n",
        "    \n",
        "    # Measure effect (simplified metric: L2 norm of difference)\n",
        "    effect = source_diff.norm().item()\n",
        "    \n",
        "    return effect\n",
        "\n",
        "\n",
        "# Test path patching\n",
        "clean_text = \"When Mary and John went to the store, Mary gave a drink to\"\n",
        "corrupted_text = \"When Mary and John went to the store, Alice gave a drink to\"\n",
        "\n",
        "clean_input = tokenizer(clean_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "corrupted_input = tokenizer(corrupted_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Test path from layer 2, head 0 to layer 6, head 3\n",
        "effect = path_patch(model, clean_input, corrupted_input, \n",
        "                   source_layer=2, source_head=0,\n",
        "                   target_layer=6, target_head=3,\n",
        "                   composition_type='K')\n",
        "\n",
        "print(f\"Path effect (layer 2, head 0 → layer 6, head 3): {effect:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Finding Induction Circuits\n",
        "\n",
        "Let's identify the induction circuit using systematic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_previous_token_heads(model, tokenizer, test_texts):\n",
        "    \"\"\"\n",
        "    Find attention heads that attend from each token to the previous token.\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model\n",
        "        tokenizer: Tokenizer\n",
        "        test_texts: List of test strings\n",
        "    \n",
        "    Returns:\n",
        "        scores: [n_layers, n_heads] array of previous-token scores\n",
        "    \"\"\"\n",
        "    n_layers = model.config.n_layer\n",
        "    n_heads = model.config.n_head\n",
        "    \n",
        "    scores = np.zeros((n_layers, n_heads))\n",
        "    \n",
        "    for text in test_texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, output_attentions=True)\n",
        "            attentions = outputs.attentions\n",
        "        \n",
        "        for layer_idx in range(n_layers):\n",
        "            # Get attention weights [batch, n_heads, seq_len, seq_len]\n",
        "            attn = attentions[layer_idx][0]  # Remove batch dim\n",
        "            \n",
        "            for head_idx in range(n_heads):\n",
        "                head_attn = attn[head_idx]  # [seq_len, seq_len]\n",
        "                \n",
        "                # Check if this head attends to previous token\n",
        "                # For each position i, check attention to position i-1\n",
        "                prev_token_attn = 0\n",
        "                for i in range(1, head_attn.shape[0]):\n",
        "                    prev_token_attn += head_attn[i, i-1].item()\n",
        "                \n",
        "                # Normalize by sequence length\n",
        "                prev_token_attn /= max(1, head_attn.shape[0] - 1)\n",
        "                scores[layer_idx, head_idx] += prev_token_attn\n",
        "    \n",
        "    # Average over test texts\n",
        "    scores /= len(test_texts)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "\n",
        "def detect_induction_heads(model, tokenizer, test_patterns):\n",
        "    \"\"\"\n",
        "    Find attention heads that implement induction (pattern copying).\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model\n",
        "        tokenizer: Tokenizer\n",
        "        test_patterns: List of (pattern, continuation) tuples\n",
        "    \n",
        "    Returns:\n",
        "        scores: [n_layers, n_heads] array of induction scores\n",
        "    \"\"\"\n",
        "    n_layers = model.config.n_layer\n",
        "    n_heads = model.config.n_head\n",
        "    \n",
        "    scores = np.zeros((n_layers, n_heads))\n",
        "    \n",
        "    for pattern, continuation in test_patterns:\n",
        "        # Create induction test: [A][B] ... [A] -> should attend to B\n",
        "        text = f\"{pattern} {continuation} ... {pattern}\"\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, output_attentions=True)\n",
        "            attentions = outputs.attentions\n",
        "        \n",
        "        # Find positions of the repeated pattern\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        pattern_tokens = tokenizer.tokenize(pattern)\n",
        "        \n",
        "        for layer_idx in range(n_layers):\n",
        "            attn = attentions[layer_idx][0]\n",
        "            \n",
        "            for head_idx in range(n_heads):\n",
        "                head_attn = attn[head_idx]\n",
        "                \n",
        "                # Check if final position attends to the continuation token\n",
        "                # This is a simplified heuristic\n",
        "                if head_attn.shape[0] > 2:\n",
        "                    induction_score = head_attn[-1, 1].item()  # Last token attending to position after first pattern\n",
        "                    scores[layer_idx, head_idx] += induction_score\n",
        "    \n",
        "    scores /= len(test_patterns)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "\n",
        "# Test on example patterns\n",
        "test_texts = [\n",
        "    \"The quick brown fox jumps over\",\n",
        "    \"When Mary and John went to\",\n",
        "    \"In the beginning there was\"\n",
        "]\n",
        "\n",
        "test_patterns = [\n",
        "    (\"Mary\", \"and\"),\n",
        "    (\"the\", \"quick\"),\n",
        "    (\"cat\", \"sat\")\n",
        "]\n",
        "\n",
        "print(\"Finding previous-token heads...\")\n",
        "prev_token_scores = detect_previous_token_heads(model, tokenizer, test_texts)\n",
        "\n",
        "print(\"\\nFinding induction heads...\")\n",
        "induction_scores = detect_induction_heads(model, tokenizer, test_patterns)\n",
        "\n",
        "# Find top heads\n",
        "print(\"\\nTop 5 Previous-Token Heads:\")\n",
        "prev_token_flat = prev_token_scores.flatten()\n",
        "top_prev_indices = np.argsort(prev_token_flat)[-5:][::-1]\n",
        "for idx in top_prev_indices:\n",
        "    layer = idx // model.config.n_head\n",
        "    head = idx % model.config.n_head\n",
        "    print(f\"  Layer {layer}, Head {head}: {prev_token_scores[layer, head]:.4f}\")\n",
        "\n",
        "print(\"\\nTop 5 Induction Heads:\")\n",
        "induction_flat = induction_scores.flatten()\n",
        "top_induction_indices = np.argsort(induction_flat)[-5:][::-1]\n",
        "for idx in top_induction_indices:\n",
        "    layer = idx // model.config.n_head\n",
        "    head = idx % model.config.n_head\n",
        "    print(f\"  Layer {layer}, Head {head}: {induction_scores[layer, head]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Previous-token heads\n",
        "im1 = axes[0].imshow(prev_token_scores, aspect='auto', cmap='viridis')\n",
        "axes[0].set_xlabel('Head')\n",
        "axes[0].set_ylabel('Layer')\n",
        "axes[0].set_title('Previous-Token Head Scores')\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# Induction heads\n",
        "im2 = axes[1].imshow(induction_scores, aspect='auto', cmap='viridis')\n",
        "axes[1].set_xlabel('Head')\n",
        "axes[1].set_ylabel('Layer')\n",
        "axes[1].set_title('Induction Head Scores')\n",
        "plt.colorbar(im2, ax=axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: K-Composition Analysis for Induction\n",
        "\n",
        "Test if induction heads use K-composition with previous-token heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_composition_type(model, clean_input, corrupted_input,\n",
        "                         source_layer, source_head,\n",
        "                         target_layer, target_head):\n",
        "    \"\"\"\n",
        "    Test Q, K, and V composition separately to determine composition type.\n",
        "    \n",
        "    Returns:\n",
        "        Dict with scores for each composition type\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for comp_type in ['Q', 'K', 'V']:\n",
        "        effect = path_patch(model, clean_input, corrupted_input,\n",
        "                          source_layer, source_head,\n",
        "                          target_layer, target_head,\n",
        "                          composition_type=comp_type)\n",
        "        results[comp_type] = effect\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "# Test composition between top previous-token head and top induction head\n",
        "# Using the top heads we found earlier\n",
        "prev_idx = top_prev_indices[0]\n",
        "prev_layer = prev_idx // model.config.n_head\n",
        "prev_head = prev_idx % model.config.n_head\n",
        "\n",
        "ind_idx = top_induction_indices[0]\n",
        "ind_layer = ind_idx // model.config.n_head\n",
        "ind_head = ind_idx % model.config.n_head\n",
        "\n",
        "print(f\"Testing composition: Layer {prev_layer} Head {prev_head} → Layer {ind_layer} Head {ind_head}\")\n",
        "\n",
        "composition_results = test_composition_type(\n",
        "    model, clean_input, corrupted_input,\n",
        "    prev_layer, prev_head,\n",
        "    ind_layer, ind_head\n",
        ")\n",
        "\n",
        "print(\"\\nComposition Type Scores:\")\n",
        "for comp_type, score in composition_results.items():\n",
        "    print(f\"  {comp_type}-composition: {score:.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(8, 5))\n",
        "comp_types = list(composition_results.keys())\n",
        "comp_scores = list(composition_results.values())\n",
        "plt.bar(comp_types, comp_scores, color=['#ff7f0e', '#2ca02c', '#1f77b4'])\n",
        "plt.ylabel('Path Effect')\n",
        "plt.title('Composition Type Analysis for Induction Circuit')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nExpected: K-composition should have the highest score for induction circuits.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Binding Circuit Analysis (Q-Composition)\n",
        "\n",
        "Test Q-composition for attribute-entity binding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_binding_circuit(model, tokenizer):\n",
        "    \"\"\"\n",
        "    Test for binding circuits using attribute-entity examples.\n",
        "    \"\"\"\n",
        "    # Clean: correct binding\n",
        "    clean_text = \"The tall person and the short person walked. The tall person sat.\"\n",
        "    \n",
        "    # Corrupted: swapped attributes\n",
        "    corrupted_text = \"The short person and the tall person walked. The tall person sat.\"\n",
        "    \n",
        "    clean_input = tokenizer(clean_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    corrupted_input = tokenizer(corrupted_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    \n",
        "    # Search for binding heads\n",
        "    n_layers = model.config.n_layer\n",
        "    n_heads = model.config.n_head\n",
        "    \n",
        "    binding_scores = np.zeros((n_layers, n_heads))\n",
        "    \n",
        "    # Test Q-composition for all head pairs\n",
        "    print(\"Searching for binding circuit (this may take a moment)...\")\n",
        "    \n",
        "    for source_layer in range(n_layers // 2):  # Early layers\n",
        "        for source_head in range(n_heads):\n",
        "            for target_layer in range(source_layer + 1, n_layers):  # Later layers\n",
        "                for target_head in range(n_heads):\n",
        "                    effect = path_patch(model, clean_input, corrupted_input,\n",
        "                                      source_layer, source_head,\n",
        "                                      target_layer, target_head,\n",
        "                                      composition_type='Q')\n",
        "                    \n",
        "                    binding_scores[target_layer, target_head] += effect\n",
        "    \n",
        "    return binding_scores\n",
        "\n",
        "\n",
        "# Find binding circuit\n",
        "binding_scores = test_binding_circuit(model, tokenizer)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(binding_scores, aspect='auto', cmap='plasma')\n",
        "plt.xlabel('Head')\n",
        "plt.ylabel('Layer')\n",
        "plt.title('Binding Circuit Scores (Q-Composition)')\n",
        "plt.colorbar(label='Path Effect')\n",
        "plt.show()\n",
        "\n",
        "# Top binding heads\n",
        "print(\"\\nTop 5 Binding Heads:\")\n",
        "binding_flat = binding_scores.flatten()\n",
        "top_binding_indices = np.argsort(binding_flat)[-5:][::-1]\n",
        "for idx in top_binding_indices:\n",
        "    layer = idx // model.config.n_head\n",
        "    head = idx % model.config.n_head\n",
        "    print(f\"  Layer {layer}, Head {head}: {binding_scores[layer, head]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Token vs Concept Induction\n",
        "\n",
        "Test the dual-route model: token-level vs concept-level induction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_token_vs_concept_induction(model, tokenizer):\n",
        "    \"\"\"\n",
        "    Compare token-level and concept-level induction.\n",
        "    \"\"\"\n",
        "    # Token induction test: exact token repetition\n",
        "    token_test = \"When Alice and Bob went to the store, Alice gave it to\"\n",
        "    \n",
        "    # Concept induction test: semantic association\n",
        "    # (Note: This is simplified - real test would involve edited model weights)\n",
        "    concept_test = \"When Paris and London are cities, Paris is the capital of\"\n",
        "    \n",
        "    token_input = tokenizer(token_test, return_tensors=\"pt\").to(device)\n",
        "    concept_input = tokenizer(concept_test, return_tensors=\"pt\").to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Token route prediction\n",
        "        token_outputs = model(**token_input, output_attentions=True, output_hidden_states=True)\n",
        "        token_logits = token_outputs.logits[0, -1, :]\n",
        "        token_probs = torch.softmax(token_logits, dim=-1)\n",
        "        token_top = torch.topk(token_probs, 5)\n",
        "        \n",
        "        # Concept route prediction\n",
        "        concept_outputs = model(**concept_input, output_attentions=True, output_hidden_states=True)\n",
        "        concept_logits = concept_outputs.logits[0, -1, :]\n",
        "        concept_probs = torch.softmax(concept_logits, dim=-1)\n",
        "        concept_top = torch.topk(concept_probs, 5)\n",
        "    \n",
        "    print(\"Token Induction Test:\")\n",
        "    print(f\"  Input: {token_test}\")\n",
        "    print(\"  Top predictions:\")\n",
        "    for prob, idx in zip(token_top.values, token_top.indices):\n",
        "        token_text = tokenizer.decode([idx])\n",
        "        print(f\"    {token_text}: {prob:.4f}\")\n",
        "    \n",
        "    print(\"\\nConcept Induction Test:\")\n",
        "    print(f\"  Input: {concept_test}\")\n",
        "    print(\"  Top predictions:\")\n",
        "    for prob, idx in zip(concept_top.values, concept_top.indices):\n",
        "        token_text = tokenizer.decode([idx])\n",
        "        print(f\"    {token_text}: {prob:.4f}\")\n",
        "    \n",
        "    # Analyze which layers contribute most to each route\n",
        "    print(\"\\nAnalyzing route contributions...\")\n",
        "    \n",
        "    # Attention contribution (token route)\n",
        "    token_attn_contribution = 0\n",
        "    for layer_attn in token_outputs.attentions:\n",
        "        # Sum attention weights (simplified metric)\n",
        "        token_attn_contribution += layer_attn.sum().item()\n",
        "    \n",
        "    concept_attn_contribution = 0\n",
        "    for layer_attn in concept_outputs.attentions:\n",
        "        concept_attn_contribution += layer_attn.sum().item()\n",
        "    \n",
        "    print(f\"Token route attention sum: {token_attn_contribution:.2f}\")\n",
        "    print(f\"Concept route attention sum: {concept_attn_contribution:.2f}\")\n",
        "\n",
        "\n",
        "test_token_vs_concept_induction(model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Automated Circuit Discovery (ACDC-style)\n",
        "\n",
        "Implement a simplified version of automated circuit discovery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def automated_circuit_discovery(model, clean_input, corrupted_input, threshold=0.1):\n",
        "    \"\"\"\n",
        "    Simplified ACDC algorithm for finding circuits.\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model\n",
        "        clean_input: Clean input\n",
        "        corrupted_input: Corrupted input\n",
        "        threshold: Minimum path effect to include in circuit\n",
        "    \n",
        "    Returns:\n",
        "        circuit_edges: List of (source, target, effect) tuples\n",
        "    \"\"\"\n",
        "    n_layers = model.config.n_layer\n",
        "    n_heads = model.config.n_head\n",
        "    \n",
        "    circuit_edges = []\n",
        "    \n",
        "    print(\"Running automated circuit discovery...\")\n",
        "    print(f\"Testing {n_layers * n_heads} components...\")\n",
        "    \n",
        "    # Test all possible edges (simplified: only adjacent layers)\n",
        "    for source_layer in range(n_layers - 1):\n",
        "        for source_head in range(n_heads):\n",
        "            for target_layer in range(source_layer + 1, min(source_layer + 3, n_layers)):\n",
        "                for target_head in range(n_heads):\n",
        "                    # Test this edge\n",
        "                    effect = path_patch(model, clean_input, corrupted_input,\n",
        "                                      source_layer, source_head,\n",
        "                                      target_layer, target_head,\n",
        "                                      composition_type='K')  # Test K-composition\n",
        "                    \n",
        "                    if effect > threshold:\n",
        "                        circuit_edges.append((\n",
        "                            (source_layer, source_head),\n",
        "                            (target_layer, target_head),\n",
        "                            effect\n",
        "                        ))\n",
        "    \n",
        "    # Sort by effect size\n",
        "    circuit_edges.sort(key=lambda x: x[2], reverse=True)\n",
        "    \n",
        "    return circuit_edges\n",
        "\n",
        "\n",
        "# Run circuit discovery\n",
        "circuit = automated_circuit_discovery(model, clean_input, corrupted_input, threshold=0.5)\n",
        "\n",
        "print(f\"\\nDiscovered {len(circuit)} edges in the circuit:\")\n",
        "print(\"\\nTop 10 edges:\")\n",
        "for i, (source, target, effect) in enumerate(circuit[:10]):\n",
        "    src_layer, src_head = source\n",
        "    tgt_layer, tgt_head = target\n",
        "    print(f\"{i+1}. L{src_layer}H{src_head} → L{tgt_layer}H{tgt_head}: {effect:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the discovered circuit\n",
        "def visualize_circuit(circuit_edges, n_layers, n_heads, top_k=20):\n",
        "    \"\"\"\n",
        "    Visualize circuit as a graph.\n",
        "    \"\"\"\n",
        "    # Create adjacency matrix\n",
        "    adj_matrix = np.zeros((n_layers * n_heads, n_layers * n_heads))\n",
        "    \n",
        "    for source, target, effect in circuit_edges[:top_k]:\n",
        "        src_idx = source[0] * n_heads + source[1]\n",
        "        tgt_idx = target[0] * n_heads + target[1]\n",
        "        adj_matrix[src_idx, tgt_idx] = effect\n",
        "    \n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(adj_matrix, cmap='YlOrRd', aspect='auto')\n",
        "    plt.colorbar(label='Path Effect')\n",
        "    plt.xlabel('Target Component (Layer * 12 + Head)')\n",
        "    plt.ylabel('Source Component (Layer * 12 + Head)')\n",
        "    plt.title(f'Circuit Connectivity (Top {top_k} edges)')\n",
        "    \n",
        "    # Add grid lines between layers\n",
        "    for layer in range(1, n_layers):\n",
        "        plt.axhline(y=layer * n_heads - 0.5, color='white', linewidth=0.5, alpha=0.5)\n",
        "        plt.axvline(x=layer * n_heads - 0.5, color='white', linewidth=0.5, alpha=0.5)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_circuit(circuit, model.config.n_layer, model.config.n_head, top_k=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Circuit Minimality Testing\n",
        "\n",
        "Test if each component is necessary for the circuit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_circuit_minimality(model, circuit_edges, clean_input, target_output):\n",
        "    \"\"\"\n",
        "    Test if each edge in the circuit is necessary.\n",
        "    \n",
        "    Args:\n",
        "        model: The model\n",
        "        circuit_edges: List of circuit edges\n",
        "        clean_input: Input to test\n",
        "        target_output: Expected output token\n",
        "    \n",
        "    Returns:\n",
        "        necessity_scores: How much performance drops when each edge is removed\n",
        "    \"\"\"\n",
        "    necessity_scores = []\n",
        "    \n",
        "    # Baseline: full circuit performance\n",
        "    with torch.no_grad():\n",
        "        baseline_outputs = model(**clean_input)\n",
        "        baseline_logits = baseline_outputs.logits[0, -1, :]\n",
        "        baseline_prob = torch.softmax(baseline_logits, dim=-1)[target_output].item()\n",
        "    \n",
        "    print(f\"Baseline probability for target: {baseline_prob:.4f}\")\n",
        "    print(\"\\nTesting necessity of each edge...\")\n",
        "    \n",
        "    # Test ablating each edge (simplified: we'll use a proxy metric)\n",
        "    for i, (source, target, effect) in enumerate(circuit_edges[:10]):  # Test top 10\n",
        "        # In a full implementation, we would actually ablate this edge\n",
        "        # Here we use the effect size as a proxy for necessity\n",
        "        necessity = effect / baseline_prob if baseline_prob > 0 else 0\n",
        "        necessity_scores.append(necessity)\n",
        "        \n",
        "        src_layer, src_head = source\n",
        "        tgt_layer, tgt_head = target\n",
        "        print(f\"Edge {i+1}: L{src_layer}H{src_head} → L{tgt_layer}H{tgt_head}\")\n",
        "        print(f\"  Necessity score: {necessity:.4f}\")\n",
        "    \n",
        "    return necessity_scores\n",
        "\n",
        "\n",
        "# Test minimality\n",
        "# For this example, let's assume we want the model to predict \"John\"\n",
        "target_token = tokenizer.encode(\" John\")[0]\n",
        "\n",
        "necessity_scores = test_circuit_minimality(model, circuit, clean_input, target_token)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(len(necessity_scores)), necessity_scores)\n",
        "plt.xlabel('Edge Index')\n",
        "plt.ylabel('Necessity Score')\n",
        "plt.title('Circuit Edge Necessity')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Circuit Faithfulness Testing\n",
        "\n",
        "Test if the circuit works on out-of-distribution examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_circuit_faithfulness(model, circuit_edges, test_cases):\n",
        "    \"\"\"\n",
        "    Test if the discovered circuit generalizes to new examples.\n",
        "    \n",
        "    Args:\n",
        "        model: The model\n",
        "        circuit_edges: Discovered circuit\n",
        "        test_cases: List of (input, expected_output) pairs\n",
        "    \n",
        "    Returns:\n",
        "        success_rate: Fraction of test cases where circuit produces correct output\n",
        "    \"\"\"\n",
        "    successes = 0\n",
        "    \n",
        "    print(\"Testing circuit faithfulness on new examples...\\n\")\n",
        "    \n",
        "    for i, (test_input, expected) in enumerate(test_cases):\n",
        "        inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits[0, -1, :]\n",
        "            predicted = torch.argmax(logits).item()\n",
        "            predicted_token = tokenizer.decode([predicted])\n",
        "        \n",
        "        success = expected.lower() in predicted_token.lower()\n",
        "        if success:\n",
        "            successes += 1\n",
        "        \n",
        "        print(f\"Test {i+1}:\")\n",
        "        print(f\"  Input: {test_input}\")\n",
        "        print(f\"  Expected: {expected}\")\n",
        "        print(f\"  Predicted: {predicted_token}\")\n",
        "        print(f\"  Status: {'✓' if success else '✗'}\")\n",
        "        print()\n",
        "    \n",
        "    success_rate = successes / len(test_cases)\n",
        "    print(f\"Overall success rate: {success_rate:.2%}\")\n",
        "    \n",
        "    return success_rate\n",
        "\n",
        "\n",
        "# Test cases for induction\n",
        "test_cases = [\n",
        "    (\"When Alice and Bob went shopping, Alice bought\", \"Bob\"),\n",
        "    (\"The cat and the dog played together. The cat chased\", \"dog\"),\n",
        "    (\"During the meeting, Sarah and Tom disagreed. Sarah said\", \"Tom\"),\n",
        "    (\"In Paris and London, I visited Paris first and then\", \"London\"),\n",
        "    (\"The red car and blue car raced. The red car won and\", \"blue\")\n",
        "]\n",
        "\n",
        "faithfulness_score = test_circuit_faithfulness(model, circuit, test_cases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 9: Comparing Circuit Architectures\n",
        "\n",
        "Compare induction and binding circuits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary comparison\n",
        "print(\"Circuit Architecture Comparison\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nInduction Circuit:\")\n",
        "print(\"  Primary Composition: K-composition\")\n",
        "print(\"  Components: 2 heads (previous-token + induction)\")\n",
        "print(\"  Layer span: Typically 2-6 layers apart\")\n",
        "print(\"  Function: Pattern copying / in-context learning\")\n",
        "print(\"  Key insight: Modifies what gets attended TO (keys)\")\n",
        "\n",
        "print(\"\\nBinding Circuit:\")\n",
        "print(\"  Primary Composition: Q-composition\")\n",
        "print(\"  Components: 3-5 heads (attribute + entity + binding + query)\")\n",
        "print(\"  Layer span: Distributed across 4-8 layers\")\n",
        "print(\"  Function: Attribute-entity association\")\n",
        "print(\"  Key insight: Modifies WHERE to attend FROM (queries)\")\n",
        "\n",
        "print(\"\\nConcept Induction (Dual-Route):\")\n",
        "print(\"  Primary Composition: Both attention (token) and MLP (concept)\")\n",
        "print(\"  Components: Attention heads + MLP layers\")\n",
        "print(\"  Layer span: Full model\")\n",
        "print(\"  Function: Pattern copying with semantic fallback\")\n",
        "print(\"  Key insight: Redundant circuits for robustness\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 10: Your Project Circuit Analysis\n",
        "\n",
        "Template for analyzing circuits for your concept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Template for your project\n",
        "print(\"Week 5 Project Template: Circuit Discovery for Your Concept\\n\")\n",
        "\n",
        "print(\"1. Define your concept and create test cases\")\n",
        "MY_CONCEPT = \"[Your concept here]\"\n",
        "my_test_cases = [\n",
        "    # (input, expected_output)\n",
        "    # Add your test cases\n",
        "]\n",
        "\n",
        "print(\"\\n2. Create clean and corrupted examples for path patching\")\n",
        "my_clean_examples = [\n",
        "    # Examples where your concept is present\n",
        "]\n",
        "\n",
        "my_corrupted_examples = [\n",
        "    # Examples where your concept is absent/altered\n",
        "]\n",
        "\n",
        "print(\"\\n3. Run automated circuit discovery\")\n",
        "# Use the functions above to find your circuit\n",
        "\n",
        "print(\"\\n4. Determine composition type (Q/K/V)\")\n",
        "# Test composition channels\n",
        "\n",
        "print(\"\\n5. Test minimality (ablation)\")\n",
        "# Remove components and measure impact\n",
        "\n",
        "print(\"\\n6. Test faithfulness (out-of-distribution)\")\n",
        "# Validate on new examples\n",
        "\n",
        "print(\"\\n7. Compare to known circuit types\")\n",
        "# Is your circuit more like induction, binding, or something novel?\n",
        "\n",
        "print(\"\\n8. Document your findings\")\n",
        "# Create circuit diagram, write mechanistic explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "In this exercise, you've learned to:\n",
        "- Implement path patching to trace information flow\n",
        "- Find induction circuits using systematic search\n",
        "- Analyze composition types (Q/K/V)\n",
        "- Compare different circuit architectures\n",
        "- Test circuit minimality and faithfulness\n",
        "\n",
        "For your project:\n",
        "1. Use these techniques to discover the circuit for your concept\n",
        "2. Create detailed circuit diagrams\n",
        "3. Test thoroughly on diverse examples\n",
        "4. Compare your circuit to known patterns\n",
        "5. Provide mechanistic explanations\n",
        "\n",
        "The goal is to move from \"this component is important\" (Week 4) to \"this is exactly how the model computes my concept\" (Week 5)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
