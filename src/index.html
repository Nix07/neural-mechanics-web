<!DOCTYPE html>
<html lang="en">
<!-- Neural Mechanics Course Website - Spring 2026 -->
<head>
  <meta charset="UTF-8">
  <title>CS 7180: Neural Mechanics</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 40px auto;
      padding: 0 20px;
      line-height: 1.6;
      background-color: #f9f9f9;
    }

    header {
      display: flex;
      align-items: center;
      margin-bottom: 30px;
    }

    header img {
      height: 60px;
      margin-right: 20px;
    }

    h1 {
      margin: 0;
      font-size: 1.8em;
    }

    section {
      margin-bottom: 40px;
    }

    h2 {
      font-size: 1.4em;
      margin-bottom: 10px;
      border-bottom: 1px solid #ccc;
      padding-bottom: 4px;
    }

    a {
      color: #0055a4;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    /* Table styling for lectures */
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 10px;
    }

    th,
    td {
      border: 1px solid #ccc;
      padding: 8px;
      text-align: left;
    }

    th {
      background-color: #f0f0f0;
    }

    /* Compact staff row */
    .staff-row {
      display: flex;
      gap: 30px;
      align-items: center;
      margin-bottom: 20px;
    }

    .staff-member {
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .staff-member img {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      object-fit: cover;
      border: 2px solid #ddd;
    }

    .staff-member .info {
      line-height: 1.3;
    }

    .staff-member .name {
      font-weight: bold;
    }

    .staff-member .role {
      font-size: 0.85em;
      color: #666;
    }

    h4 {
      margin: 15px 0 5px 0;
      font-size: 1em;
    }
  </style>
</head>

<body>

  <header>
    <img src="imgs/ne.png" alt="Northeastern Logo">
    <h1>CS 7180 (AI Special Topics): Neural Mechanics</h1>
  </header>
  <p style="margin-top: -20px; margin-bottom: 15px;">Northeastern University, Spring 2026</p>

  <div class="staff-row">
    <div class="staff-member">
      <img src="imgs/staff/david.webp" alt="David Bau">
      <div class="info">
        <div class="name"><a href="https://baulab.info/">David Bau</a></div>
        <div class="role">Instructor</div>
      </div>
    </div>
    <div class="staff-member">
      <img src="imgs/staff/np.jpg" alt="Nikhil Prakash">
      <div class="info">
        <div class="name"><a href="https://nix07.github.io/">Nikhil Prakash</a></div>
        <div class="role">TA</div>
      </div>
    </div>
  </div>

  <p>
    Modern AI systems are powerful but opaque: even their creators do not fully understand what the billions of artificial neurons are doing inside. This class teaches methods for probing neural networks to uncover <em>what concepts they have learned</em> and <em>where those concepts are encoded</em>.
  </p>
  <p>
    Interdisciplinary teams of a domain-expert PhD student, one or more CS/ML graduate students, and a <a href="https://baulab.info/">Bau Lab</a> mentor will aim to produce publication-quality research papers studying how LLMs encode concepts from fields outside CS, an area often neglected in interpretability research. Teams will target venues like NeurIPS, ICLR, or ICML. <strong>Prerequisites:</strong> linear algebra, probability, deep learning, Python, PyTorch.
  </p>
  <p>
    <strong>Time:</strong> Tuesday 11:45 am &ndash; 1:25 pm, Thursday 2:50 pm &ndash; 4:30 pm<br>
    <strong>Location:</strong> <a href="https://maps.app.goo.gl/gJZ8xNmZKvQjCLLr5" target="_blank">Hayden Hall 321</a>
  </p>

  <section id="syllabus">
    <h2>Syllabus</h2>

    This schedule is provisional and subject to change.

    <table>
      <thead>
        <tr>
          <th>Week</th>
          <th>Tuesday</th>
          <th>Thursday</th>
          <th>Assignments / Notes</th>
        </tr>
      </thead>
      <tbody>
        <!-- Week 0: Introduction -->
        <tr>
          <td>0</td>
          <td colspan="2"><a href="week0.html">Introduction</a><br>Course structure, goals, and introduction to mechanistic interpretability.<br><small>Thu Jan 8</small><br><small>Read: <a href="papers/cummings-1988-conceiving-the-research-question.pdf">Cummings (FINER)</a>, <a href="papers/hamming-1986-you-and-your-research.pdf">Hamming</a>, <a href="papers/nielsen-2004-principles-of-effective-research.pdf">Nielsen</a></small>
          </td>
          <td>Form teams; establish team Google Drive; brainstorm 2-3 candidate concepts</td>
        </tr>
        <!-- Week 1: Foundations -->
        <tr>
          <td>1</td>
          <td><a href="week1.html">Foundations</a><br>Logit lens, intermediate representations, and the vocabulary of mechanistic interpretability.<br><small>Tue Jan 13</small><br><small>Read: <a href="https://arxiv.org/abs/2405.00208">Primer</a>, <a href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens">Logit Lens</a>, <a href="https://arxiv.org/abs/2402.10588">Latent Language</a></small>
          </td>
          <td><strong>Project Pitches</strong><br><small>Thu Jan 15</small></td>
          <td>Hand in pitch Google Doc; each team presents their pitch</td>
        </tr>
        <!-- Week 2: Steering -->
        <tr>
          <td>2</td>
          <td><a href="week2.html">Steering</a><br>Controlling model behavior by manipulating distributed neural representation vectors.<br><small>Tue Jan 20</small><br><small>Read: <a href="papers/piantadosi-2024-concepts-are-vectors.pdf">Piantadosi</a>, <a href="https://arxiv.org/abs/2209.10652">Superposition</a>, <a href="https://arxiv.org/abs/2306.03341">ITI</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Jan 22</small></td>
          <td>First plot-a-thon slides; logit lens or Neuronpedia explorations</td>
        </tr>
        <!-- Week 3: Evaluation Methodology -->
        <tr>
          <td>3</td>
          <td><a href="week3.html">Evaluation Methodology</a><br>Creating evaluation datasets; measuring LLM behavior with cloze tasks, LLM-as-judge, model-written evaluations.<br><small>Tue Jan 27</small><br><small>Read: <a href="https://arxiv.org/abs/2212.09251">Model-Written Evals</a>, <a href="https://arxiv.org/abs/2306.05685">LLM-as-Judge</a>, <a href="https://arxiv.org/abs/1909.01066">LAMA</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Jan 29</small></td>
          <td>Plot-a-thon: benchmark findings and model choices; create GitHub</td>
        </tr>
        <!-- Week 4: Representation Geometry -->
        <tr>
          <td>4</td>
          <td><a href="week4.html">Representation Geometry</a><br>What does a concept look like? PCA visualization, linear directions, and geometric structure.<br><small>Tue Feb 3</small><br><small>Read: <a href="https://arxiv.org/abs/2310.06824">Geometry of Truth</a>, <a href="https://arxiv.org/abs/2310.15154">Sentiment</a>, <a href="https://arxiv.org/abs/2511.18162">Vector Arithmetic</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Feb 5</small></td>
          <td>Push interactive visualizations to project website</td>
        </tr>
        <!-- Week 5: Causal Localization -->
        <tr>
          <td>5</td>
          <td><a href="week5.html">Causal Localization</a><br>Where are facts and functions computed? Causal tracing, activation patching, and function vectors.<br><small>Tue Feb 10</small><br><small>Read: <a href="https://arxiv.org/abs/2202.05262">ROME</a>, <a href="https://arxiv.org/abs/2310.15213">Function Vectors</a>, <a href="https://arxiv.org/abs/2402.14811">Entity Tracking</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Feb 12</small></td>
          <td>Start Overleaf; causal mediation experiments</td>
        </tr>
        <!-- Week 6: Probes -->
        <tr>
          <td>6</td>
          <td><a href="week6.html">Probes</a><br>Is the information there? Training classifiers to decode concepts, plus methodological pitfalls.<br><small>Tue Feb 17</small><br><small>Read: <a href="https://arxiv.org/abs/1711.11279">TCAV</a>, <a href="https://arxiv.org/abs/1909.03368">Probing Control Tasks</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Feb 19</small></td>
          <td>Reproducible experiment infrastructure; trained concept probe</td>
        </tr>
        <!-- Week 7: Attribution -->
        <tr>
          <td>7</td>
          <td><a href="week7.html">Attribution</a><br>Which input tokens matter? Integrated gradients, faithful attribution, and RAG analysis.<br><small>Tue Feb 24</small><br><small>Read: <a href="https://arxiv.org/abs/1703.01365">Integrated Gradients</a>, <a href="https://arxiv.org/abs/2406.13663">MIRAGE</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Feb 26</small></td>
          <td>Draft intro framing your research story; input attribution</td>
        </tr>
        <!-- Spring Break -->
        <tr style="background-color: #e8e8e8;">
          <td>&mdash;</td>
          <td colspan="2"><em>Spring Break</em><br><small>Mar 2&ndash;6</small></td>
          <td>No class</td>
        </tr>
        <!-- Week 8: Circuits -->
        <tr>
          <td>8</td>
          <td><a href="week8.html">Circuits</a><br>Reverse-engineering end-to-end algorithms: induction heads, ACDC, and automated circuit discovery.<br><small>Tue Mar 10</small><br><small>Read: <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">Induction Heads</a>, <a href="https://arxiv.org/abs/2304.14997">ACDC</a>, <a href="https://arxiv.org/abs/2403.17806">Faithfulness</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Mar 12</small></td>
          <td>Refine hypotheses; repeat experiments; circuits analysis</td>
        </tr>
        <!-- Week 9: Training Dynamics & Model Editing -->
        <tr>
          <td>9</td>
          <td><a href="week9.html">Training Dynamics & Model Editing</a><br>How circuits emerge during training; surgical fact editing with MEMIT.<br><small>Tue Mar 17</small><br><small>Read: <a href="https://arxiv.org/abs/2301.05217">Grokking</a>, <a href="https://arxiv.org/abs/2210.07229">MEMIT</a>, <a href="https://arxiv.org/abs/2512.16902">In-Context Algebra</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Mar 19</small></td>
          <td>Triangulate: scale or diversity experiments</td>
        </tr>
        <!-- Week 10: Human Understanding & Self-Description -->
        <tr>
          <td>10</td>
          <td><a href="week10.html">Human Understanding & Self-Description</a><br>Can interpretability help humans? Can models interpret themselves?<br><small>Tue Mar 24</small><br><small>Read: <a href="https://www.pnas.org/doi/10.1073/pnas.2406675122">Bridging the Human-AI Gap</a>, <a href="https://arxiv.org/abs/2401.06102">Patchscopes</a>, <a href="https://arxiv.org/abs/2510.08506">Neologism</a></small>
          </td>
          <td><strong>Project Updates</strong><br><small>Thu Mar 26</small></td>
          <td>More triangulation; finalize experiment results</td>
        </tr>
        <!-- Project Weeks -->
        <tr>
          <td>11</td>
          <td><a href="week11.html">How to Write a Paper</a><br><small>Tue Mar 31</small>
          </td>
          <td><strong>Peer Review Workshop</strong><br><small>Thu Apr 2</small></td>
          <td>Introduction + methods draft for peer review</td>
        </tr>
        <tr>
          <td>12</td>
          <td>Plot-a-thon: Results Discussion<br><small>Tue Apr 7</small>
          </td>
          <td><strong>Peer Review Workshop</strong><br><small>Thu Apr 9</small></td>
          <td>Complete paper draft for peer review</td>
        </tr>
        <tr>
          <td>13</td>
          <td>Guest Lecture<br><small>Tue Apr 14</small>
          </td>
          <td><strong>Paper Editing Workshop</strong><br><small>Thu Apr 16</small></td>
          <td>Editing and refinement</td>
        </tr>
        <tr>
          <td>14</td>
          <td colspan="2">Final Presentations<br><small>Tue Apr 21</small>
          </td>
          <td>Final paper due Wed Apr 22</td>
        </tr>
      </tbody>
    </table>


  </section>

  <section id="grading">
    <h2>Grading</h2>
    <ul>
      <li><strong>25%</strong> Final paper and presentation</li>
      <li><strong>25%</strong> Weekly project milestones</li>
      <li><strong>25%</strong> Peer reviews</li>
      <li><strong>25%</strong> Class participation</li>
    </ul>
  </section>

  <section id="office-hours">
    <h2>Office Hours</h2>

    <table border="1" cellpadding="5" cellspacing="0">
      <tr>
        <th>Names</th>
        <th>Day</th>
        <th>Time</th>
        <th>Location</th>
      </tr>
      <tr>
        <td>David</td>
        <td>TBD</td>
        <td>TBD</td>
        <td>TBD</td>
      </tr>
      <tr>
        <td>Nikhil</td>
        <td>TBD</td>
        <td>TBD</td>
        <td>TBD</td>
      </tr>
    </table>

  </section>

  <section id="supplementary-materials">
    <h2>Supplementary Materials</h2>
  </section>

</body>

</html>

