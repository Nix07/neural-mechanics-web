{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Exercise: Representation Visualization\n",
    "\n",
    "In this exercise, you'll gain hands-on experience with:\n",
    "- PCA for dimensionality reduction and visualization\n",
    "- Computing and visualizing concept directions\n",
    "- Exploring token embedding/unembedding geometry\n",
    "- Semantic-vector arithmetic\n",
    "- The logit lens\n",
    "- Attention pattern visualization\n",
    "- Finding and analyzing induction heads\n",
    "- Distinguishing token vs. concept induction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch numpy matplotlib seaborn scikit-learn einops circuitsvis -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from einops import rearrange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Layers: {model.config.n_layer}\")\n",
    "print(f\"Hidden size: {model.config.n_embd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Algebra Review and PCA\n",
    "\n",
    "Let's start with the mathematical foundations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector operations\n",
    "v = np.array([3, 4])\n",
    "w = np.array([1, 2])\n",
    "\n",
    "# Dot product\n",
    "dot_product = np.dot(v, w)\n",
    "print(f\"Dot product: {dot_product}\")\n",
    "\n",
    "# Norm\n",
    "norm_v = np.linalg.norm(v)\n",
    "print(f\"Norm of v: {norm_v}\")\n",
    "\n",
    "# Cosine similarity\n",
    "cosine_sim = dot_product / (np.linalg.norm(v) * np.linalg.norm(w))\n",
    "print(f\"Cosine similarity: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Example: 2D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated 2D data\n",
    "np.random.seed(42)\n",
    "n_points = 100\n",
    "x = np.random.randn(n_points)\n",
    "y = 2 * x + np.random.randn(n_points) * 0.5\n",
    "data = np.column_stack([x, y])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original data\n",
    "ax1.scatter(data[:, 0], data[:, 1], alpha=0.6)\n",
    "ax1.set_title('Original Data')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.axis('equal')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# PCA transformed\n",
    "ax2.scatter(data_pca[:, 0], data_pca[:, 1], alpha=0.6, color='orange')\n",
    "ax2.set_title('After PCA (Principal Components)')\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC2')\n",
    "ax2.axis('equal')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"PC1 captures {pca.explained_variance_ratio_[0]:.1%} of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualizing Activation Vectors with PCA\n",
    "\n",
    "Now let's apply PCA to real model activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(texts, layer_idx=-1, position=-1):\n",
    "    \"\"\"\n",
    "    Extract activation vectors for a list of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of strings\n",
    "        layer_idx: Which layer to extract from\n",
    "        position: Which token position (-1 for last)\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (len(texts), hidden_size)\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    \n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states\n",
    "            \n",
    "            # Extract from specific layer and position\n",
    "            act = hidden_states[layer_idx][0, position, :]\n",
    "            activations.append(act.cpu().numpy())\n",
    "    \n",
    "    return np.array(activations)\n",
    "\n",
    "# Test with some words\n",
    "words = [\"The cat\", \"The dog\", \"The democracy\", \"The freedom\"]\n",
    "acts = get_activations(words, layer_idx=-1)\n",
    "print(f\"Activation shape: {acts.shape}\")\n",
    "print(f\"  {acts.shape[0]} words × {acts.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations for semantic categories\n",
    "animal_words = [\"The cat\", \"The dog\", \"The elephant\", \"The tiger\", \"The bird\", \"The fish\"]\n",
    "country_words = [\"The France\", \"The Germany\", \"The Italy\", \"The Spain\", \"The Japan\", \"The China\"]\n",
    "abstract_words = [\"The democracy\", \"The freedom\", \"The justice\", \"The truth\", \"The beauty\", \"The love\"]\n",
    "\n",
    "all_words = animal_words + country_words + abstract_words\n",
    "labels = ['animal'] * len(animal_words) + ['country'] * len(country_words) + ['abstract'] * len(abstract_words)\n",
    "\n",
    "# Get activations\n",
    "activations = get_activations(all_words, layer_idx=-1)\n",
    "\n",
    "# Apply PCA to reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "activations_2d = pca.fit_transform(activations)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = {'animal': 'blue', 'country': 'green', 'abstract': 'red'}\n",
    "\n",
    "for i, (word, label) in enumerate(zip(all_words, labels)):\n",
    "    plt.scatter(activations_2d[i, 0], activations_2d[i, 1], \n",
    "                c=colors[label], s=100, alpha=0.6, label=label if i == labels.index(label) else \"\")\n",
    "    plt.annotate(word.replace(\"The \", \"\"), \n",
    "                (activations_2d[i, 0], activations_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('PCA Visualization of Word Representations')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Do you see semantic clusters? Are animals grouped together? Countries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Mass Mean-Difference Vectors\n",
    "\n",
    "Extract concept directions using contrastive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_concept_direction(positive_texts, negative_texts, layer_idx=-1):\n",
    "    \"\"\"\n",
    "    Compute mass mean-difference vector for a concept.\n",
    "    \"\"\"\n",
    "    pos_acts = get_activations(positive_texts, layer_idx=layer_idx)\n",
    "    neg_acts = get_activations(negative_texts, layer_idx=layer_idx)\n",
    "    \n",
    "    direction = pos_acts.mean(axis=0) - neg_acts.mean(axis=0)\n",
    "    \n",
    "    return direction\n",
    "\n",
    "# Example: Positive sentiment direction\n",
    "positive_texts = [\n",
    "    \"This is wonderful and amazing\",\n",
    "    \"I feel so happy and joyful\",\n",
    "    \"Everything is going great\",\n",
    "    \"This is fantastic and delightful\",\n",
    "    \"I absolutely love this\"\n",
    "]\n",
    "\n",
    "negative_texts = [\n",
    "    \"This is terrible and awful\",\n",
    "    \"I feel so sad and depressed\",\n",
    "    \"Everything is going badly\",\n",
    "    \"This is horrible and dreadful\",\n",
    "    \"I absolutely hate this\"\n",
    "]\n",
    "\n",
    "sentiment_direction = compute_concept_direction(positive_texts, negative_texts, layer_idx=-1)\n",
    "print(f\"Sentiment direction shape: {sentiment_direction.shape}\")\n",
    "print(f\"Direction magnitude: {np.linalg.norm(sentiment_direction):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_classifier(texts, direction):\n",
    "    \"\"\"\n",
    "    Classify texts based on projection onto concept direction.\n",
    "    \"\"\"\n",
    "    acts = get_activations(texts, layer_idx=-1)\n",
    "    scores = acts @ direction  # Dot product with direction\n",
    "    return scores\n",
    "\n",
    "# Test classifier\n",
    "test_texts = [\n",
    "    \"This movie was absolutely brilliant\",      # Positive\n",
    "    \"I had a terrible experience\",              # Negative\n",
    "    \"The weather is nice today\",                # Positive\n",
    "    \"This is the worst thing ever\",             # Negative\n",
    "    \"I'm feeling pretty good\",                  # Positive\n",
    "    \"Everything is falling apart\"               # Negative\n",
    "]\n",
    "\n",
    "true_labels = [1, 0, 1, 0, 1, 0]  # 1=positive, 0=negative\n",
    "\n",
    "scores = euclidean_classifier(test_texts, sentiment_direction)\n",
    "predictions = (scores > 0).astype(int)\n",
    "\n",
    "print(\"Text | True | Pred | Score\")\n",
    "print(\"-\" * 60)\n",
    "for text, true, pred, score in zip(test_texts, true_labels, predictions, scores):\n",
    "    print(f\"{text[:40]:40s} | {true} | {pred} | {score:+.3f}\")\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Concept Direction in PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations for all texts\n",
    "all_texts = positive_texts + negative_texts\n",
    "all_labels = [1] * len(positive_texts) + [0] * len(negative_texts)\n",
    "all_acts = get_activations(all_texts, layer_idx=-1)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "acts_2d = pca.fit_transform(all_acts)\n",
    "\n",
    "# Project direction into PCA space\n",
    "direction_2d = pca.transform([sentiment_direction])[0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red' if label == 0 else 'blue' for label in all_labels]\n",
    "plt.scatter(acts_2d[:, 0], acts_2d[:, 1], c=colors, s=100, alpha=0.6)\n",
    "\n",
    "# Draw concept direction as arrow\n",
    "center = acts_2d.mean(axis=0)\n",
    "plt.arrow(center[0], center[1], direction_2d[0]*2, direction_2d[1]*2,\n",
    "         head_width=0.5, head_length=0.3, fc='green', ec='green', linewidth=2, label='Sentiment direction')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Sentiment Concept Direction in Activation Space')\n",
    "plt.legend(['Negative', 'Positive', 'Direction'])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Your Concept Direction\n",
    "\n",
    "Create a concept direction for your project concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your concept\n",
    "my_positive_texts = [\n",
    "    # Examples with your concept\n",
    "]\n",
    "\n",
    "my_negative_texts = [\n",
    "    # Examples without your concept\n",
    "]\n",
    "\n",
    "# Compute direction\n",
    "# my_direction = compute_concept_direction(my_positive_texts, my_negative_texts)\n",
    "\n",
    "# Test classifier\n",
    "# Test and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Token Embedding and Unembedding Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access embedding and unembedding matrices\n",
    "embedding_matrix = model.transformer.wte.weight.detach().cpu().numpy()\n",
    "unembedding_matrix = model.lm_head.weight.detach().cpu().numpy()\n",
    "\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
    "print(f\"  {embedding_matrix.shape[0]} tokens × {embedding_matrix.shape[1]} dimensions\")\n",
    "print(f\"\\nUnembedding matrix shape: {unembedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some interesting tokens\n",
    "words_to_viz = [\n",
    "    \"cat\", \"dog\", \"animal\",\n",
    "    \"France\", \"Germany\", \"country\",\n",
    "    \"happy\", \"sad\", \"emotion\",\n",
    "    \"the\", \"and\", \"is\"\n",
    "]\n",
    "\n",
    "# Get token IDs and embeddings\n",
    "token_ids = [tokenizer.encode(word, add_special_tokens=False)[0] for word in words_to_viz]\n",
    "token_embeddings = embedding_matrix[token_ids]\n",
    "\n",
    "# PCA to 2D\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(token_embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100, alpha=0.6)\n",
    "\n",
    "for i, word in enumerate(words_to_viz):\n",
    "    plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Token Embedding Space (PCA)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Semantic-Vector Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_embedding(word):\n",
    "    \"\"\"Get embedding vector for a token.\"\"\"\n",
    "    token_id = tokenizer.encode(word, add_special_tokens=False)[0]\n",
    "    return embedding_matrix[token_id]\n",
    "\n",
    "def find_nearest_tokens(vector, k=5, exclude_ids=None):\n",
    "    \"\"\"Find k nearest tokens to a vector.\"\"\"\n",
    "    if exclude_ids is None:\n",
    "        exclude_ids = set()\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = embedding_matrix @ vector / (np.linalg.norm(embedding_matrix, axis=1) * np.linalg.norm(vector))\n",
    "    \n",
    "    # Get top k\n",
    "    top_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        if idx not in exclude_ids:\n",
    "            results.append((idx, similarities[idx]))\n",
    "            if len(results) >= k:\n",
    "                break\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Classic example: king - man + woman ≈ queen\n",
    "king = get_token_embedding(\"king\")\n",
    "man = get_token_embedding(\"man\")\n",
    "woman = get_token_embedding(\"woman\")\n",
    "\n",
    "result = king - man + woman\n",
    "\n",
    "# Find nearest tokens\n",
    "king_id = tokenizer.encode(\"king\", add_special_tokens=False)[0]\n",
    "nearest = find_nearest_tokens(result, k=10, exclude_ids={king_id})\n",
    "\n",
    "print(\"king - man + woman ≈\")\n",
    "for idx, sim in nearest:\n",
    "    token = tokenizer.decode([idx])\n",
    "    print(f\"  {token:15s} (similarity: {sim:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Arithmetic Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paris - France + Germany ≈ Berlin\n",
    "paris = get_token_embedding(\"Paris\")\n",
    "france = get_token_embedding(\"France\")\n",
    "germany = get_token_embedding(\"Germany\")\n",
    "\n",
    "result = paris - france + germany\n",
    "nearest = find_nearest_tokens(result, k=5)\n",
    "\n",
    "print(\"Paris - France + Germany ≈\")\n",
    "for idx, sim in nearest:\n",
    "    print(f\"  {tokenizer.decode([idx]):15s} (similarity: {sim:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Design Your Own Analogies\n",
    "\n",
    "Test semantic arithmetic relevant to your concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create analogies for your concept\n",
    "# Example: A - B + C ≈ ?\n",
    "\n",
    "# Does your concept support vector arithmetic?\n",
    "# What does this tell you about how it's represented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: The Logit Lens\n",
    "\n",
    "Peek into intermediate layers to see what the model is \"thinking\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_lens(text, position=-1, top_k=5):\n",
    "    \"\"\"\n",
    "    Apply logit lens to see predictions at each layer.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        position: Token position to analyze\n",
    "        top_k: Number of top predictions to show\n",
    "    \n",
    "    Returns:\n",
    "        List of (layer, top_tokens) tuples\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for layer_idx, hidden_state in enumerate(hidden_states):\n",
    "        # Extract activation at position\n",
    "        activation = hidden_state[0, position, :]\n",
    "        \n",
    "        # Apply unembedding\n",
    "        logits = model.lm_head(activation)\n",
    "        probs = torch.softmax(logits, dim=0)\n",
    "        \n",
    "        # Get top k\n",
    "        top_probs, top_indices = torch.topk(probs, top_k)\n",
    "        \n",
    "        top_tokens = [(tokenizer.decode([idx]), prob.item()) \n",
    "                     for idx, prob in zip(top_indices, top_probs)]\n",
    "        \n",
    "        results.append((layer_idx, top_tokens))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test on factual recall\n",
    "text = \"The capital of France is\"\n",
    "results = logit_lens(text, position=-1, top_k=3)\n",
    "\n",
    "print(f\"Logit lens for: '{text}'\\n\")\n",
    "print(\"Layer | Top 3 Predictions\")\n",
    "print(\"-\" * 60)\n",
    "for layer, top_tokens in results:\n",
    "    tokens_str = \", \".join([f\"{tok} ({prob:.3f})\" for tok, prob in top_tokens])\n",
    "    print(f\"  {layer:2d}  | {tokens_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logit_lens(text, target_tokens, position=-1):\n",
    "    \"\"\"\n",
    "    Plot how probabilities of specific tokens evolve across layers.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    # Get token IDs for targets\n",
    "    target_ids = [tokenizer.encode(tok, add_special_tokens=False)[0] for tok in target_tokens]\n",
    "    \n",
    "    # Track probabilities across layers\n",
    "    layer_probs = {tok: [] for tok in target_tokens}\n",
    "    \n",
    "    for hidden_state in hidden_states:\n",
    "        activation = hidden_state[0, position, :]\n",
    "        logits = model.lm_head(activation)\n",
    "        probs = torch.softmax(logits, dim=0)\n",
    "        \n",
    "        for tok, tok_id in zip(target_tokens, target_ids):\n",
    "            layer_probs[tok].append(probs[tok_id].item())\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for tok in target_tokens:\n",
    "        plt.plot(range(len(layer_probs[tok])), layer_probs[tok], marker='o', label=tok)\n",
    "    \n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'Logit Lens: Prediction Evolution for \"{text}\"')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example\n",
    "plot_logit_lens(\"The capital of France is\", [\"Paris\", \"London\", \"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** At which layer does the model \"know\" the answer? How do wrong answers evolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Visualizing Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_patterns(text):\n",
    "    \"\"\"\n",
    "    Extract attention patterns for all heads and layers.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "        attentions = outputs.attentions\n",
    "    \n",
    "    # Convert to numpy\n",
    "    return [attn[0].cpu().numpy() for attn in attentions]\n",
    "\n",
    "def plot_attention_head(attention_matrix, tokens, layer, head):\n",
    "    \"\"\"\n",
    "    Visualize attention pattern as heatmap.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(attention_matrix, \n",
    "                xticklabels=tokens, \n",
    "                yticklabels=tokens,\n",
    "                cmap='viridis',\n",
    "                cbar_kws={'label': 'Attention Weight'})\n",
    "    plt.xlabel('Key (attending to)')\n",
    "    plt.ylabel('Query (attending from)')\n",
    "    plt.title(f'Attention Pattern: Layer {layer}, Head {head}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test\n",
    "text = \"The cat sat on the mat and the dog played\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "attentions = get_attention_patterns(text)\n",
    "\n",
    "# Plot a specific head\n",
    "layer_idx = 5\n",
    "head_idx = 0\n",
    "plot_attention_head(attentions[layer_idx][head_idx], tokens, layer_idx, head_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Interesting Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_previous_token_heads(attentions, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Find heads that primarily attend to the previous token.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for layer_idx, layer_attn in enumerate(attentions):\n",
    "        num_heads = layer_attn.shape[0]\n",
    "        \n",
    "        for head_idx in range(num_heads):\n",
    "            attn_matrix = layer_attn[head_idx]\n",
    "            \n",
    "            # Check attention to previous token (i-1)\n",
    "            prev_scores = []\n",
    "            for i in range(1, attn_matrix.shape[0]):\n",
    "                prev_scores.append(attn_matrix[i, i-1])\n",
    "            \n",
    "            avg_prev = np.mean(prev_scores)\n",
    "            \n",
    "            if avg_prev > threshold:\n",
    "                results.append((layer_idx, head_idx, avg_prev))\n",
    "    \n",
    "    return results\n",
    "\n",
    "prev_heads = find_previous_token_heads(attentions)\n",
    "print(\"Previous-Token Heads:\")\n",
    "for layer, head, score in prev_heads:\n",
    "    print(f\"  Layer {layer}, Head {head}: {score:.3f} avg attention to previous token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Finding and Visualizing Induction Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create induction-friendly text\n",
    "induction_text = \"Alice went to the store. Bob went to the park. Alice went to the\"\n",
    "tokens = tokenizer.tokenize(induction_text)\n",
    "attentions = get_attention_patterns(induction_text)\n",
    "\n",
    "print(f\"Text: {induction_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"\\nLooking for induction pattern at final 'the' (after second 'Alice')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Induction Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_induction_heads(text, repeated_token=\"Alice\"):\n",
    "    \"\"\"\n",
    "    Find heads that show induction behavior.\n",
    "    Looks for strong attention from second occurrence to what followed first occurrence.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    attentions = get_attention_patterns(text)\n",
    "    \n",
    "    # Find positions of repeated token\n",
    "    token_positions = [i for i, tok in enumerate(tokens) if repeated_token in tok]\n",
    "    \n",
    "    if len(token_positions) < 2:\n",
    "        print(f\"Need at least 2 occurrences of '{repeated_token}'\")\n",
    "        return []\n",
    "    \n",
    "    first_pos = token_positions[0]\n",
    "    second_pos = token_positions[1]\n",
    "    \n",
    "    print(f\"First '{repeated_token}' at position {first_pos}\")\n",
    "    print(f\"Second '{repeated_token}' at position {second_pos}\")\n",
    "    print(f\"Looking for attention from {second_pos+1} to {first_pos+1}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for layer_idx, layer_attn in enumerate(attentions):\n",
    "        num_heads = layer_attn.shape[0]\n",
    "        \n",
    "        for head_idx in range(num_heads):\n",
    "            attn_matrix = layer_attn[head_idx]\n",
    "            \n",
    "            # Check if position after second occurrence attends to position after first\n",
    "            if second_pos + 1 < attn_matrix.shape[0]:\n",
    "                induction_score = attn_matrix[second_pos + 1, first_pos + 1]\n",
    "                \n",
    "                if induction_score > 0.2:  # Threshold\n",
    "                    results.append((layer_idx, head_idx, induction_score))\n",
    "    \n",
    "    return results\n",
    "\n",
    "induction_heads = detect_induction_heads(induction_text, \"Alice\")\n",
    "\n",
    "print(\"Potential Induction Heads:\")\n",
    "for layer, head, score in sorted(induction_heads, key=lambda x: x[2], reverse=True):\n",
    "    print(f\"  Layer {layer}, Head {head}: {score:.3f} induction score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Induction Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the strongest induction head\n",
    "if induction_heads:\n",
    "    best_layer, best_head, best_score = induction_heads[0]\n",
    "    plot_attention_head(attentions[best_layer][best_head], tokens, best_layer, best_head)\n",
    "    print(f\"\\nThis head shows induction behavior: position after 'Alice' #2 attends to position after 'Alice' #1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Token vs. Concept Induction\n",
    "\n",
    "Test the difference between literal token copying and semantic pattern copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_induction_type(text, expected_token=None):\n",
    "    \"\"\"\n",
    "    Test if model performs induction and what type.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]\n",
    "        probs = torch.softmax(logits, dim=0)\n",
    "    \n",
    "    top_k = 5\n",
    "    top_probs, top_indices = torch.topk(probs, top_k)\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    if expected_token:\n",
    "        print(f\"Expected (if induction works): {expected_token}\")\n",
    "    print(f\"\\nTop {top_k} predictions:\")\n",
    "    for prob, idx in zip(top_probs, top_indices):\n",
    "        token = tokenizer.decode([idx])\n",
    "        print(f\"  '{token}' → {prob.item():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Token-level induction: exact match\n",
    "print(\"=\" * 60)\n",
    "print(\"TOKEN-LEVEL INDUCTION (exact token match)\")\n",
    "print(\"=\" * 60)\n",
    "test_induction_type(\"foo bar baz foo bar baz foo\", expected_token=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept-level induction: semantic pattern\n",
    "print(\"=\" * 60)\n",
    "print(\"CONCEPT-LEVEL INDUCTION (semantic pattern)\")\n",
    "print(\"=\" * 60)\n",
    "test_induction_type(\n",
    "    \"The capital of France is Paris. The capital of Germany is Berlin. The capital of Italy is\",\n",
    "    expected_token=\"Rome\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Token Words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multi-token words\n",
    "multi_token_text = \"San Francisco is a city. Los Angeles is a city. San Francisco is\"\n",
    "tokens = tokenizer.tokenize(multi_token_text)\n",
    "print(f\"Text: {multi_token_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"\\nNote: 'San Francisco' is tokenized as multiple tokens\")\n",
    "print(f\"      'Los Angeles' is also multiple tokens\")\n",
    "\n",
    "# Get attention patterns\n",
    "attentions = get_attention_patterns(multi_token_text)\n",
    "\n",
    "# Analyze attention from final position\n",
    "print(f\"\\nAnalyzing attention from final 'is' (after second 'San Francisco')\")\n",
    "print(f\"Does it attend to last token of 'San Francisco' (concept) or first token (token-level)?\")\n",
    "\n",
    "# You can visualize specific heads here to see the pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.1: Test Your Concept for Induction\n",
    "\n",
    "Does your concept involve any pattern-copying behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design tests for your concept\n",
    "# - Does it involve pattern repetition?\n",
    "# - Is it token-level or concept-level?\n",
    "# - Can you visualize relevant attention heads?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Putting It All Together\n",
    "\n",
    "Complete analysis workflow for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for your project assignment\n",
    "\n",
    "# 1. Collect activations\n",
    "my_concept_examples = [\n",
    "    # Your examples\n",
    "]\n",
    "no_concept_examples = [\n",
    "    # Contrasting examples\n",
    "]\n",
    "\n",
    "# 2. PCA visualization\n",
    "# all_acts = get_activations(my_concept_examples + no_concept_examples)\n",
    "# Apply PCA and plot\n",
    "\n",
    "# 3. Compute concept direction\n",
    "# my_direction = compute_concept_direction(my_concept_examples, no_concept_examples)\n",
    "\n",
    "# 4. Test Euclidean classifier\n",
    "# Evaluate accuracy\n",
    "\n",
    "# 5. Logit lens analysis\n",
    "# Track prediction evolution across layers\n",
    "\n",
    "# 6. Semantic arithmetic (if applicable)\n",
    "# Test compositional properties\n",
    "\n",
    "# 7. Attention analysis (if relevant)\n",
    "# Visualize important attention patterns\n",
    "\n",
    "# Document all findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer these in your project writeup:\n",
    "\n",
    "1. **PCA Visualization**: Do examples with/without your concept cluster separately in PCA space? What does this tell you?\n",
    "\n",
    "2. **Geometric Structure**: Is your concept well-represented as a linear direction? Does the Euclidean classifier work well?\n",
    "\n",
    "3. **Layer Analysis**: Which layer(s) show the clearest geometric structure for your concept? Why?\n",
    "\n",
    "4. **Logit Lens**: At what layer does the model \"know\" about your concept? How do predictions evolve?\n",
    "\n",
    "5. **Semantic Arithmetic**: Does your concept support vector arithmetic? What analogies work or fail?\n",
    "\n",
    "6. **Attention Patterns**: (If applicable) Do you see interpretable attention patterns related to your concept?\n",
    "\n",
    "7. **Induction**: (If applicable) Does your concept involve token-level or concept-level pattern copying?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For your assignment:\n",
    "1. Create comprehensive visualizations for your concept\n",
    "2. Analyze geometric structure across layers\n",
    "3. Test linear representation hypothesis\n",
    "4. Apply logit lens to understand prediction evolution\n",
    "5. Explore attention patterns if relevant\n",
    "6. Document insights about how your concept is represented\n",
    "\n",
    "These visualization techniques will be essential for understanding your concept in upcoming weeks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
