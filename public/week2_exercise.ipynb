{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Exercise: Steering Language Models\n",
    "\n",
    "In this exercise, you'll gain hands-on experience with:\n",
    "- Loading and examining transformer architecture\n",
    "- Extracting and visualizing activation vectors\n",
    "- Finding induction heads\n",
    "- Creating steering vectors from contrastive pairs\n",
    "- Applying steering to control model behavior\n",
    "- Using Neuronpedia to find concept features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch numpy matplotlib einops circuitsvis -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from einops import rearrange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Examining a Transformer\n",
    "\n",
    "Let's load GPT-2 and explore its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 small\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = model.to(device)\n",
    "model.eval()  # Evaluation mode\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of layers: {model.config.n_layer}\")\n",
    "print(f\"Hidden size: {model.config.n_embd}\")\n",
    "print(f\"Number of attention heads: {model.config.n_head}\")\n",
    "print(f\"Vocabulary size: {model.config.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Architecture Components\n",
    "\n",
    "Let's look at the main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(\"=\"*80)\n",
    "for name, module in model.named_modules():\n",
    "    if len(list(module.children())) == 0:  # Leaf modules only\n",
    "        print(f\"{name}: {module.__class__.__name__}\")\n",
    "        if name.count('.') <= 2:  # Don't go too deep\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key components:\n",
    "- `transformer.wte`: Token embeddings (encoder)\n",
    "- `transformer.h`: Transformer layers (attention + MLP)\n",
    "- `lm_head`: Output layer (decoder)\n",
    "\n",
    "Each transformer block has:\n",
    "- Attention (multihead)\n",
    "- MLP (feedforward)\n",
    "- Layer normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extracting Activation Vectors\n",
    "\n",
    "Let's extract activations at different layers to see internal representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(text, layer_idx=-1):\n",
    "    \"\"\"\n",
    "    Extract activation vectors at a specific layer.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        layer_idx: Which layer to extract from (-1 = last layer)\n",
    "    \n",
    "    Returns:\n",
    "        activations: [num_tokens, hidden_size] tensor\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # output_hidden_states=True gives us all layer activations\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # hidden_states is a tuple of (num_layers+1) tensors\n",
    "        # Each is [batch_size, seq_len, hidden_size]\n",
    "        hidden_states = outputs.hidden_states\n",
    "        \n",
    "        # Extract the desired layer\n",
    "        activations = hidden_states[layer_idx][0]  # Remove batch dimension\n",
    "    \n",
    "    return activations.cpu()\n",
    "\n",
    "# Test it\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "\n",
    "# Get activations from last layer\n",
    "activations = get_activations(text, layer_idx=-1)\n",
    "print(f\"\\nActivation shape: {activations.shape}\")\n",
    "print(f\"  {activations.shape[0]} tokens × {activations.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Activations Across Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer_activations(text, token_idx=-1):\n",
    "    \"\"\"\n",
    "    Show how activation magnitudes change across layers for a specific token.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    # Extract activation norms at each layer\n",
    "    norms = []\n",
    "    for layer_activations in hidden_states:\n",
    "        # Get the specific token's activation\n",
    "        token_activation = layer_activations[0, token_idx, :]\n",
    "        # Compute L2 norm\n",
    "        norms.append(token_activation.norm().item())\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(norms, marker='o')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Activation Magnitude (L2 norm)')\n",
    "    plt.title(f'Activation magnitude across layers for token: \"{tokenizer.tokenize(text)[token_idx]}\"')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize\n",
    "text = \"The cat sat on the mat\"\n",
    "visualize_layer_activations(text, token_idx=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Compare Activation Patterns\n",
    "\n",
    "Extract activations for similar vs. dissimilar words and compute their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return (v1 @ v2) / (v1.norm() * v2.norm())\n",
    "\n",
    "# Compare \"cat\" vs \"dog\" vs \"democracy\"\n",
    "words = [\"The cat\", \"The dog\", \"The democracy\"]\n",
    "activations_list = []\n",
    "\n",
    "for word in words:\n",
    "    act = get_activations(word, layer_idx=-1)\n",
    "    # Get the last token's activation\n",
    "    activations_list.append(act[-1])\n",
    "\n",
    "# Compute pairwise similarities\n",
    "print(\"Cosine Similarities:\")\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i < j:\n",
    "            sim = cosine_similarity(activations_list[i], activations_list[j])\n",
    "            print(f\"  {word1} ↔ {word2}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are \"cat\" and \"dog\" more similar to each other than to \"democracy\"? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Finding Induction Heads\n",
    "\n",
    "Let's identify attention heads that perform induction (pattern copying)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_patterns(text):\n",
    "    \"\"\"\n",
    "    Extract attention patterns from all heads.\n",
    "    \n",
    "    Returns:\n",
    "        List of attention matrices, one per layer\n",
    "        Each is [num_heads, seq_len, seq_len]\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "        attentions = outputs.attentions  # Tuple of attention tensors\n",
    "    \n",
    "    # Convert to list of numpy arrays\n",
    "    return [attn[0].cpu().numpy() for attn in attentions]\n",
    "\n",
    "# Test with induction-inducing text\n",
    "induction_text = \"Alice Bob Alice Bob Alice Bob Alice\"\n",
    "tokens = tokenizer.tokenize(induction_text)\n",
    "print(f\"Tokens: {tokens}\")\n",
    "\n",
    "attentions = get_attention_patterns(induction_text)\n",
    "print(f\"\\nNumber of layers: {len(attentions)}\")\n",
    "print(f\"Attention shape per layer: {attentions[0].shape}\")\n",
    "print(f\"  {attentions[0].shape[0]} heads × {attentions[0].shape[1]} query tokens × {attentions[0].shape[2]} key tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Attention Patterns\n",
    "\n",
    "Look for heads that attend to previous token positions (induction head candidates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_head(attention_matrix, tokens, layer, head):\n",
    "    \"\"\"\n",
    "    Plot attention pattern for a specific head.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(attention_matrix, cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Attention Weight')\n",
    "    plt.xlabel('Key Position (attending to)')\n",
    "    plt.ylabel('Query Position (attending from)')\n",
    "    plt.title(f'Layer {layer}, Head {head}')\n",
    "    \n",
    "    # Add token labels\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "    plt.yticks(range(len(tokens)), tokens)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Look at a few heads\n",
    "# Layer 5, Head 1 is often an induction head in GPT-2 small\n",
    "layer_idx = 5\n",
    "head_idx = 1\n",
    "\n",
    "attention_matrix = attentions[layer_idx][head_idx]\n",
    "plot_attention_head(attention_matrix, tokens, layer_idx, head_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Find Previous-Token Heads\n",
    "\n",
    "A \"previous token head\" attends strongly to position i-1. Let's find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_previous_token_heads(attentions):\n",
    "    \"\"\"\n",
    "    Find heads that predominantly attend to the previous token.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for layer_idx, layer_attn in enumerate(attentions):\n",
    "        num_heads = layer_attn.shape[0]\n",
    "        \n",
    "        for head_idx in range(num_heads):\n",
    "            attn_matrix = layer_attn[head_idx]\n",
    "            \n",
    "            # For each query position i (except first),\n",
    "            # check if it attends mostly to position i-1\n",
    "            prev_token_scores = []\n",
    "            for i in range(1, attn_matrix.shape[0]):\n",
    "                # Attention from position i to position i-1\n",
    "                prev_token_scores.append(attn_matrix[i, i-1])\n",
    "            \n",
    "            # Average attention to previous token\n",
    "            avg_prev = np.mean(prev_token_scores)\n",
    "            \n",
    "            if avg_prev > 0.3:  # Threshold\n",
    "                results.append((layer_idx, head_idx, avg_prev))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Find previous-token heads\n",
    "prev_heads = detect_previous_token_heads(attentions)\n",
    "print(\"Previous-Token Heads (candidates for induction head cooperation):\")\n",
    "for layer, head, score in prev_heads:\n",
    "    print(f\"  Layer {layer}, Head {head}: {score:.3f} avg attention to previous token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Induction Behavior\n",
    "\n",
    "Let's see if the model actually performs induction copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_induction(pattern_text):\n",
    "    \"\"\"\n",
    "    Test if the model can copy patterns.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(pattern_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]  # Last position\n",
    "        probs = torch.softmax(logits, dim=0)\n",
    "    \n",
    "    # Get top predictions\n",
    "    top_k = 5\n",
    "    top_probs, top_indices = torch.topk(probs, top_k)\n",
    "    \n",
    "    print(f\"Pattern: '{pattern_text}'\")\n",
    "    print(f\"Top {top_k} next token predictions:\")\n",
    "    for prob, idx in zip(top_probs, top_indices):\n",
    "        token = tokenizer.decode([idx])\n",
    "        print(f\"  '{token}' → {prob.item():.4f}\")\n",
    "\n",
    "# Test induction\n",
    "test_induction(\"foo bar baz foo bar baz foo\")\n",
    "print()\n",
    "test_induction(\"Once upon a time, there was a cat. Once upon a time, there was a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the model predict tokens that continue the pattern? This is evidence of induction heads at work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Extracting Steering Vectors\n",
    "\n",
    "Now let's create steering vectors using contrastive pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_steering_vector(positive_prompts, negative_prompts, layer_idx=-1):\n",
    "    \"\"\"\n",
    "    Extract a steering vector from contrastive examples.\n",
    "    \n",
    "    Args:\n",
    "        positive_prompts: List of texts with the target concept\n",
    "        negative_prompts: List of texts without the target concept\n",
    "        layer_idx: Which layer to extract from\n",
    "    \n",
    "    Returns:\n",
    "        Steering vector (mean difference)\n",
    "    \"\"\"\n",
    "    pos_activations = []\n",
    "    neg_activations = []\n",
    "    \n",
    "    # Extract activations for positive examples\n",
    "    for prompt in positive_prompts:\n",
    "        acts = get_activations(prompt, layer_idx)\n",
    "        # Use the last token's activation\n",
    "        pos_activations.append(acts[-1])\n",
    "    \n",
    "    # Extract activations for negative examples\n",
    "    for prompt in negative_prompts:\n",
    "        acts = get_activations(prompt, layer_idx)\n",
    "        neg_activations.append(acts[-1])\n",
    "    \n",
    "    # Compute mean difference\n",
    "    pos_mean = torch.stack(pos_activations).mean(dim=0)\n",
    "    neg_mean = torch.stack(neg_activations).mean(dim=0)\n",
    "    \n",
    "    steering_vector = pos_mean - neg_mean\n",
    "    \n",
    "    return steering_vector\n",
    "\n",
    "# Example: Create a \"happiness\" steering vector\n",
    "happy_prompts = [\n",
    "    \"I am so happy and joyful\",\n",
    "    \"This is wonderful and delightful\",\n",
    "    \"I feel great and excited\",\n",
    "    \"Everything is amazing\",\n",
    "]\n",
    "\n",
    "sad_prompts = [\n",
    "    \"I am so sad and depressed\",\n",
    "    \"This is terrible and awful\",\n",
    "    \"I feel bad and upset\",\n",
    "    \"Everything is horrible\",\n",
    "]\n",
    "\n",
    "happiness_vector = extract_steering_vector(happy_prompts, sad_prompts, layer_idx=-1)\n",
    "print(f\"Extracted happiness steering vector\")\n",
    "print(f\"Shape: {happiness_vector.shape}\")\n",
    "print(f\"Magnitude: {happiness_vector.norm():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Create Your Own Steering Vector\n",
    "\n",
    "Design contrastive pairs for a concept relevant to your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your concept steering vector\n",
    "\n",
    "my_positive_prompts = [\n",
    "    # Add prompts that exhibit your concept\n",
    "]\n",
    "\n",
    "my_negative_prompts = [\n",
    "    # Add prompts that lack your concept\n",
    "]\n",
    "\n",
    "# Extract vector\n",
    "# my_steering_vector = extract_steering_vector(my_positive_prompts, my_negative_prompts)\n",
    "# print(f\"My concept steering vector: {my_steering_vector.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Applying Steering Vectors\n",
    "\n",
    "Now let's use our steering vector to modify model behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_steering(prompt, steering_vector, layer_idx, alpha=1.0, max_length=50):\n",
    "    \"\"\"\n",
    "    Generate text with steering applied at a specific layer.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input text\n",
    "        steering_vector: Vector to add to activations\n",
    "        layer_idx: Which layer to intervene at\n",
    "        alpha: Strength of steering\n",
    "        max_length: Maximum generation length\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    steering_vector = steering_vector.to(device)\n",
    "    \n",
    "    # Register hook to modify activations\n",
    "    def steering_hook(module, input, output):\n",
    "        # output is typically a tuple (hidden_states, ...)\n",
    "        if isinstance(output, tuple):\n",
    "            hidden_states = output[0]\n",
    "        else:\n",
    "            hidden_states = output\n",
    "        \n",
    "        # Add steering vector to all positions\n",
    "        hidden_states = hidden_states + alpha * steering_vector\n",
    "        \n",
    "        if isinstance(output, tuple):\n",
    "            return (hidden_states,) + output[1:]\n",
    "        return hidden_states\n",
    "    \n",
    "    # Get the target layer\n",
    "    if layer_idx == -1:\n",
    "        layer_idx = model.config.n_layer - 1\n",
    "    \n",
    "    target_layer = model.transformer.h[layer_idx]\n",
    "    \n",
    "    # Register hook\n",
    "    handle = target_layer.register_forward_hook(steering_hook)\n",
    "    \n",
    "    # Generate with steering\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Remove hook\n",
    "    handle.remove()\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test steering\n",
    "test_prompt = \"Today I went to the park and\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NO STEERING:\")\n",
    "baseline = generate_with_steering(test_prompt, torch.zeros_like(happiness_vector), layer_idx=-1, alpha=0.0)\n",
    "print(baseline)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POSITIVE STEERING (more happy):\")\n",
    "positive = generate_with_steering(test_prompt, happiness_vector, layer_idx=-1, alpha=2.0)\n",
    "print(positive)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEGATIVE STEERING (more sad):\")\n",
    "negative = generate_with_steering(test_prompt, happiness_vector, layer_idx=-1, alpha=-2.0)\n",
    "print(negative)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Vary Steering Strength\n",
    "\n",
    "Test different values of alpha to see how steering strength affects output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple steering strengths\n",
    "test_prompt = \"The movie was\"\n",
    "alphas = [-3.0, -1.0, 0.0, 1.0, 3.0]\n",
    "\n",
    "for alpha in alphas:\n",
    "    result = generate_with_steering(\n",
    "        test_prompt, \n",
    "        happiness_vector, \n",
    "        layer_idx=-1, \n",
    "        alpha=alpha,\n",
    "        max_length=30\n",
    "    )\n",
    "    print(f\"\\nα = {alpha:+.1f}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Compare Layers\n",
    "\n",
    "Which layer is best for steering? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract steering vectors at different layers\n",
    "layers_to_test = [0, 3, 6, 9, 11]\n",
    "test_prompt = \"I think that\"\n",
    "\n",
    "for layer in layers_to_test:\n",
    "    # Extract vector at this layer\n",
    "    steering_vec = extract_steering_vector(happy_prompts, sad_prompts, layer_idx=layer)\n",
    "    \n",
    "    # Apply steering\n",
    "    result = generate_with_steering(\n",
    "        test_prompt,\n",
    "        steering_vec,\n",
    "        layer_idx=layer,\n",
    "        alpha=2.0,\n",
    "        max_length=30\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLayer {layer:2d}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which layers produce the strongest steering effects? Why might middle or late layers work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Introduction to Neuronpedia\n",
    "\n",
    "Neuronpedia provides pre-computed SAE features. Let's explore how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Neuronpedia\n",
    "\n",
    "1. **Visit**: Go to [neuronpedia.org](https://www.neuronpedia.org/)\n",
    "\n",
    "2. **Select Model**: Choose GPT-2 small or another model\n",
    "\n",
    "3. **Search Features**: Use the search bar to find concepts\n",
    "   - Example: \"positive sentiment\", \"medical\", \"legal\"\n",
    "\n",
    "4. **Examine Features**: For each feature, you can see:\n",
    "   - Examples of text that maximally activate it\n",
    "   - Which tokens trigger it\n",
    "   - Layer and feature index\n",
    "\n",
    "5. **Export Vectors**: Some versions allow downloading feature vectors\n",
    "\n",
    "### Exercise 6.1: Neuronpedia Exploration\n",
    "\n",
    "Visit Neuronpedia and:\n",
    "1. Search for features related to your concept\n",
    "2. Record 3-5 relevant features (layer, index, description)\n",
    "3. Note what kinds of examples activate each feature\n",
    "4. Compare to your contrastive steering vectors: do they capture similar patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual SAE Feature Vector (Example)\n",
    "\n",
    "If you have access to SAE weights, you can extract specific features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a placeholder - actual SAE usage requires loading trained dictionaries\n",
    "# For your project, you may:\n",
    "# 1. Download feature vectors from Neuronpedia\n",
    "# 2. Load pre-trained SAEs\n",
    "# 3. Train your own SAE (advanced)\n",
    "\n",
    "print(\"SAE features would be used similarly to steering vectors:\")\n",
    "print(\"1. Load/download feature vector from Neuronpedia\")\n",
    "print(\"2. Apply it using generate_with_steering()\")\n",
    "print(\"3. Compare results with contrastive steering vectors\")\n",
    "print(\"\\nFor this week's assignment, focus on contrastive extraction.\")\n",
    "print(\"SAE features provide an alternative that you can explore and compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Putting It All Together\n",
    "\n",
    "Complete project workflow for your concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for your project assignment\n",
    "\n",
    "# 1. Define your concept\n",
    "MY_CONCEPT = \"[Your concept here]\"\n",
    "\n",
    "# 2. Create contrastive pairs\n",
    "positive_examples = [\n",
    "    # Add 10-20 examples with your concept\n",
    "]\n",
    "\n",
    "negative_examples = [\n",
    "    # Add 10-20 examples without your concept\n",
    "]\n",
    "\n",
    "# 3. Extract steering vectors at multiple layers\n",
    "layer_vectors = {}\n",
    "for layer in [0, 3, 6, 9, 11]:\n",
    "    layer_vectors[layer] = extract_steering_vector(\n",
    "        positive_examples, \n",
    "        negative_examples, \n",
    "        layer_idx=layer\n",
    "    )\n",
    "\n",
    "# 4. Test steering on examples\n",
    "test_prompts = [\n",
    "    # Add test cases\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    # Baseline\n",
    "    baseline = generate_with_steering(\n",
    "        prompt, torch.zeros_like(layer_vectors[6]), 6, alpha=0.0\n",
    "    )\n",
    "    print(f\"  Baseline: {baseline}\")\n",
    "    \n",
    "    # Positive steering\n",
    "    positive = generate_with_steering(\n",
    "        prompt, layer_vectors[6], 6, alpha=2.0\n",
    "    )\n",
    "    print(f\"  Positive: {positive}\")\n",
    "    \n",
    "    # Negative steering\n",
    "    negative = generate_with_steering(\n",
    "        prompt, layer_vectors[6], 6, alpha=-2.0\n",
    "    )\n",
    "    print(f\"  Negative: {negative}\")\n",
    "\n",
    "# 5. Analyze and document results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer these in your project writeup:\n",
    "\n",
    "1. **Activation Patterns**: How do activation vectors for similar concepts compare? What does this tell you about distributed representations?\n",
    "\n",
    "2. **Layer Analysis**: Which layer(s) best encode your concept? Why might certain layers be better than others?\n",
    "\n",
    "3. **Steering Quality**: How does steering strength (alpha) affect:\n",
    "   - Presence of your concept\n",
    "   - Text coherence and fluency\n",
    "   - Unintended side effects\n",
    "\n",
    "4. **Contrastive Pairs**: How did you design your contrastive examples? What makes a good contrast for your concept?\n",
    "\n",
    "5. **Neuronpedia**: Did you find SAE features matching your concept? How do they compare to your extracted vectors?\n",
    "\n",
    "6. **Linear Representation**: Do your results support the linear representation hypothesis? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For your assignment:\n",
    "1. Create comprehensive contrastive datasets for your concept\n",
    "2. Extract and analyze steering vectors across layers\n",
    "3. Demonstrate successful steering on diverse examples\n",
    "4. Explore Neuronpedia for related features\n",
    "5. Document your findings and insights\n",
    "\n",
    "Save your steering vectors - you'll use them in future weeks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
