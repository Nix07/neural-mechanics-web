{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# The Geometry of Puns: Visualizing Humor in Representation Space\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nix07/neural-mechanics-web/blob/main/labs/week4/pun_geometry.ipynb)\n",
    "\n",
    "This notebook explores the **geometric structure of pun representations** in large language models, inspired by Marks & Tegmark's \"Geometry of Truth\" methodology.\n",
    "\n",
    "**Key Questions:**\n",
    "- Do puns and non-puns separate in activation space?\n",
    "- Is there a linear \"pun direction\" analogous to the \"truth direction\"?\n",
    "- At which layer does pun understanding emerge?\n",
    "\n",
    "We'll use **Llama 3 70B** via NDIF to visualize high-dimensional representations using PCA and find concept directions.\n",
    "\n",
    "## References\n",
    "- [The Geometry of Truth](https://arxiv.org/abs/2310.06824) - Marks & Tegmark\n",
    "- [Linear Representations of Sentiment](https://arxiv.org/abs/2310.15154) - Tigges et al.\n",
    "- [nnsight documentation](https://nnsight.net/)\n",
    "- [NDIF - National Deep Inference Fabric](https://ndif.us/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nnsight scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "# Use remote=True to run on NDIF's shared GPU resources\n",
    "REMOTE = True\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Llama 3 70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(\"meta-llama/Meta-Llama-3-70B\", device_map=\"auto\")\n",
    "\n",
    "print(f\"Model: {model.config._name_or_path}\")\n",
    "print(f\"Layers: {model.config.num_hidden_layers}\")\n",
    "print(f\"Hidden size: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Part 1: Prepare Pun and Non-Pun Datasets\n",
    "\n",
    "Following the Geometry of Truth methodology, we need matched pairs of pun and non-pun sentences. The key insight is that comparing similar sentences that differ only in \"pun-ness\" helps isolate the pun representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pun examples with their punchlines\n",
    "puns = [\n",
    "    \"Why do electricians make good swimmers? Because they know the current.\",\n",
    "    \"Why did the banker break up with his girlfriend? He lost interest.\",\n",
    "    \"What do you call a fish without eyes? A fsh.\",\n",
    "    \"Why don't scientists trust atoms? Because they make up everything.\",\n",
    "    \"What did the ocean say to the beach? Nothing, it just waved.\",\n",
    "    \"Why do cows wear bells? Because their horns don't work.\",\n",
    "    \"I used to hate facial hair, but then it grew on me.\",\n",
    "    \"Why did the scarecrow win an award? He was outstanding in his field.\",\n",
    "    \"What do you call a bear with no teeth? A gummy bear.\",\n",
    "    \"Why can't a bicycle stand on its own? It's two tired.\",\n",
    "    \"What do you call a fake noodle? An impasta.\",\n",
    "    \"Why did the math book look so sad? It had too many problems.\",\n",
    "    \"What do you call a sleeping dinosaur? A dino-snore.\",\n",
    "    \"Why did the golfer bring two pairs of pants? In case he got a hole in one.\",\n",
    "    \"What did the grape say when it got stepped on? Nothing, it just let out a little wine.\",\n",
    "    \"Why do seagulls fly over the sea? Because if they flew over the bay, they'd be bagels.\",\n",
    "    \"What do you call a can opener that doesn't work? A can't opener.\",\n",
    "    \"Why did the coffee file a police report? It got mugged.\",\n",
    "    \"What do you call a pig that does karate? A pork chop.\",\n",
    "    \"Why don't eggs tell jokes? They'd crack each other up.\",\n",
    "]\n",
    "\n",
    "# Non-pun sentences (literal, similar structure but no wordplay)\n",
    "non_puns = [\n",
    "    \"Why do electricians wear rubber gloves? To protect themselves from shocks.\",\n",
    "    \"Why did the banker open a new account? To manage his investments.\",\n",
    "    \"What do you call a fish that lives in freshwater? A trout.\",\n",
    "    \"Why don't scientists make assumptions? Because they need evidence.\",\n",
    "    \"What did the ocean look like at sunset? Calm and peaceful.\",\n",
    "    \"Why do cows produce milk? To feed their calves.\",\n",
    "    \"I used to avoid exercise, but then I started running.\",\n",
    "    \"Why did the scarecrow need repairs? The birds had damaged it.\",\n",
    "    \"What do you call a bear in winter? A hibernating animal.\",\n",
    "    \"Why can't a bicycle go uphill easily? The gradient is steep.\",\n",
    "    \"What do you call a fresh noodle? An al dente pasta.\",\n",
    "    \"Why did the math book look so old? It had been used for years.\",\n",
    "    \"What do you call a prehistoric reptile? A dinosaur.\",\n",
    "    \"Why did the golfer check the weather? To plan his game.\",\n",
    "    \"What did the grape taste like? Sweet and juicy.\",\n",
    "    \"Why do seagulls live by the coast? Because that's their habitat.\",\n",
    "    \"What do you call a manual can opener? A hand-operated tool.\",\n",
    "    \"Why did the coffee taste bitter? It was over-extracted.\",\n",
    "    \"What do you call a pig on a farm? Livestock.\",\n",
    "    \"Why don't eggs last forever? They spoil over time.\",\n",
    "]\n",
    "\n",
    "print(f\"Puns: {len(puns)}\")\n",
    "print(f\"Non-puns: {len(non_puns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 2: Extract Activations\n",
    "\n",
    "We'll extract hidden states at multiple layers to see where the pun/non-pun distinction emerges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(prompt, model, layer_idx, position=-1, remote=True):\n",
    "    \"\"\"\n",
    "    Get the hidden state activation at a specific layer and position.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input text\n",
    "        model: nnsight LanguageModel\n",
    "        layer_idx: Which layer to extract from\n",
    "        position: Token position (-1 = last token)\n",
    "        remote: Use NDIF remote inference\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (hidden_size,)\n",
    "    \"\"\"\n",
    "    with model.trace(prompt, remote=remote) as tracer:\n",
    "        hidden = model.model.layers[layer_idx].output[0].save()\n",
    "    \n",
    "    # Get activation at specified position\n",
    "    activation = hidden.value[0, position, :].cpu().numpy()\n",
    "    return activation\n",
    "\n",
    "def collect_activations(sentences, model, layer_idx, position=-1, remote=True):\n",
    "    \"\"\"\n",
    "    Collect activations for multiple sentences.\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (n_sentences, hidden_size)\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        act = get_activation(sentence, model, layer_idx, position, remote)\n",
    "        activations.append(act)\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(sentences)}\")\n",
    "    \n",
    "    return np.array(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations at multiple layers\n",
    "# Following Geometry of Truth, we examine early, middle, and late layers\n",
    "n_layers = model.config.num_hidden_layers\n",
    "layers_to_examine = {\n",
    "    'early': n_layers // 4,      # ~Layer 20 for 80-layer model\n",
    "    'middle': n_layers // 2,      # ~Layer 40\n",
    "    'late': 3 * n_layers // 4,    # ~Layer 60\n",
    "    'final': n_layers - 1         # Last layer\n",
    "}\n",
    "\n",
    "print(f\"Examining layers: {layers_to_examine}\")\n",
    "\n",
    "# Dictionary to store activations\n",
    "pun_activations = {}\n",
    "nonpun_activations = {}\n",
    "\n",
    "for name, layer_idx in layers_to_examine.items():\n",
    "    print(f\"\\nCollecting activations for layer {layer_idx} ({name})...\")\n",
    "    print(\"  Puns:\")\n",
    "    pun_activations[name] = collect_activations(puns, model, layer_idx, remote=REMOTE)\n",
    "    print(\"  Non-puns:\")\n",
    "    nonpun_activations[name] = collect_activations(non_puns, model, layer_idx, remote=REMOTE)\n",
    "\n",
    "print(\"\\nDone collecting activations!\")\n",
    "print(f\"Activation shape: {pun_activations['middle'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Part 3: PCA Visualization\n",
    "\n",
    "Following the Geometry of Truth paper, we use PCA to visualize the high-dimensional activations in 2D. The key question: **do puns and non-puns cluster separately?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_scatter(pun_acts, nonpun_acts, layer_name, ax=None):\n",
    "    \"\"\"\n",
    "    Create a PCA scatter plot of pun vs non-pun activations.\n",
    "    \"\"\"\n",
    "    # Combine for joint PCA\n",
    "    all_acts = np.vstack([pun_acts, nonpun_acts])\n",
    "    labels = ['pun'] * len(pun_acts) + ['non-pun'] * len(nonpun_acts)\n",
    "    \n",
    "    # Fit PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    projected = pca.fit_transform(all_acts)\n",
    "    \n",
    "    # Split back\n",
    "    pun_proj = projected[:len(pun_acts)]\n",
    "    nonpun_proj = projected[len(pun_acts):]\n",
    "    \n",
    "    # Plot\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    ax.scatter(pun_proj[:, 0], pun_proj[:, 1], c='coral', label='Puns', \n",
    "               alpha=0.7, s=100, edgecolors='darkred', linewidth=0.5)\n",
    "    ax.scatter(nonpun_proj[:, 0], nonpun_proj[:, 1], c='steelblue', label='Non-puns',\n",
    "               alpha=0.7, s=100, edgecolors='darkblue', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "    ax.set_title(f'{layer_name.capitalize()} Layer')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA plots for all examined layers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, layer_idx) in enumerate(layers_to_examine.items()):\n",
    "    plot_pca_scatter(pun_activations[name], nonpun_activations[name], \n",
    "                     f'{name} (L{layer_idx})', ax=axes[i])\n",
    "\n",
    "plt.suptitle('PCA Visualization: Puns vs Non-Puns Across Layers', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Part 4: The \"Pun Direction\"\n",
    "\n",
    "Following Marks & Tegmark, we compute the **mass mean-difference vector** between puns and non-puns. This direction should capture the essence of \"pun-ness\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pun_direction(pun_acts, nonpun_acts):\n",
    "    \"\"\"\n",
    "    Compute the pun direction as mass mean-difference.\n",
    "    \n",
    "    pun_direction = mean(pun_activations) - mean(nonpun_activations)\n",
    "    \"\"\"\n",
    "    mean_pun = np.mean(pun_acts, axis=0)\n",
    "    mean_nonpun = np.mean(nonpun_acts, axis=0)\n",
    "    \n",
    "    direction = mean_pun - mean_nonpun\n",
    "    \n",
    "    # Normalize to unit vector\n",
    "    direction_normalized = direction / np.linalg.norm(direction)\n",
    "    \n",
    "    return direction_normalized, mean_pun, mean_nonpun\n",
    "\n",
    "# Compute pun direction for each layer\n",
    "pun_directions = {}\n",
    "for name in layers_to_examine.keys():\n",
    "    direction, mean_pun, mean_nonpun = compute_pun_direction(\n",
    "        pun_activations[name], nonpun_activations[name]\n",
    "    )\n",
    "    pun_directions[name] = {\n",
    "        'direction': direction,\n",
    "        'mean_pun': mean_pun,\n",
    "        'mean_nonpun': mean_nonpun\n",
    "    }\n",
    "    \n",
    "    # Compute separation (distance between means)\n",
    "    separation = np.linalg.norm(mean_pun - mean_nonpun)\n",
    "    print(f\"{name}: mean separation = {separation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Testing the Pun Direction\n",
    "\n",
    "We can use the pun direction as a simple classifier: project each sentence onto the direction and see if puns have higher scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_direction(activations, direction):\n",
    "    \"\"\"\n",
    "    Project activations onto a direction.\n",
    "    Returns scalar scores for each example.\n",
    "    \"\"\"\n",
    "    return activations @ direction\n",
    "\n",
    "def evaluate_direction(pun_acts, nonpun_acts, direction):\n",
    "    \"\"\"\n",
    "    Evaluate how well a direction separates puns from non-puns.\n",
    "    \"\"\"\n",
    "    pun_scores = score_on_direction(pun_acts, direction)\n",
    "    nonpun_scores = score_on_direction(nonpun_acts, direction)\n",
    "    \n",
    "    # Simple threshold classifier: predict pun if score > threshold\n",
    "    all_scores = np.concatenate([pun_scores, nonpun_scores])\n",
    "    all_labels = np.array([1] * len(pun_scores) + [0] * len(nonpun_scores))\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    threshold = np.median(all_scores)\n",
    "    predictions = (all_scores > threshold).astype(int)\n",
    "    accuracy = accuracy_score(all_labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'pun_scores': pun_scores,\n",
    "        'nonpun_scores': nonpun_scores,\n",
    "        'accuracy': accuracy,\n",
    "        'threshold': threshold\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pun direction at each layer\n",
    "print(\"Classification accuracy using pun direction:\\n\")\n",
    "\n",
    "results = {}\n",
    "for name in layers_to_examine.keys():\n",
    "    result = evaluate_direction(\n",
    "        pun_activations[name],\n",
    "        nonpun_activations[name],\n",
    "        pun_directions[name]['direction']\n",
    "    )\n",
    "    results[name] = result\n",
    "    \n",
    "    print(f\"{name:8s}: {result['accuracy']*100:.1f}% accuracy\")\n",
    "    print(f\"          Pun scores: mean={np.mean(result['pun_scores']):.3f}, std={np.std(result['pun_scores']):.3f}\")\n",
    "    print(f\"          Non-pun scores: mean={np.mean(result['nonpun_scores']):.3f}, std={np.std(result['nonpun_scores']):.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, name in enumerate(layers_to_examine.keys()):\n",
    "    ax = axes[i]\n",
    "    result = results[name]\n",
    "    \n",
    "    # Histogram of scores\n",
    "    ax.hist(result['pun_scores'], bins=15, alpha=0.6, color='coral', \n",
    "            label=f'Puns (mean={np.mean(result[\"pun_scores\"]):.2f})', density=True)\n",
    "    ax.hist(result['nonpun_scores'], bins=15, alpha=0.6, color='steelblue',\n",
    "            label=f'Non-puns (mean={np.mean(result[\"nonpun_scores\"]):.2f})', density=True)\n",
    "    \n",
    "    ax.axvline(result['threshold'], color='black', linestyle='--', \n",
    "               label=f'Threshold (acc={result[\"accuracy\"]*100:.0f}%)')\n",
    "    \n",
    "    ax.set_xlabel('Projection onto Pun Direction')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{name.capitalize()} Layer')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Score Distributions: Puns vs Non-Puns Projected onto Pun Direction', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Part 5: Linear Separability Analysis\n",
    "\n",
    "Beyond the mean-difference direction, let's see how well a logistic regression classifier can separate puns from non-puns. This tests the full linear separability of the representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_linear_separability(pun_acts, nonpun_acts, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Train a logistic regression classifier and return train/test accuracy.\n",
    "    \"\"\"\n",
    "    X = np.vstack([pun_acts, nonpun_acts])\n",
    "    y = np.array([1] * len(pun_acts) + [0] * len(nonpun_acts))\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train logistic regression\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    \n",
    "    return {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'classifier': clf\n",
    "    }\n",
    "\n",
    "# Test linear separability at each layer\n",
    "print(\"Linear separability (Logistic Regression):\\n\")\n",
    "print(f\"{'Layer':<10} {'Train Acc':<12} {'Test Acc':<12}\")\n",
    "print(\"-\" * 34)\n",
    "\n",
    "separability_results = {}\n",
    "for name in layers_to_examine.keys():\n",
    "    result = test_linear_separability(\n",
    "        pun_activations[name],\n",
    "        nonpun_activations[name]\n",
    "    )\n",
    "    separability_results[name] = result\n",
    "    print(f\"{name:<10} {result['train_accuracy']*100:>8.1f}%    {result['test_accuracy']*100:>8.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Part 6: Visualize Pun Direction in PCA Space\n",
    "\n",
    "Let's visualize the pun direction overlaid on our PCA plots. If the direction aligns with the cluster separation, it confirms our linear representation hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_direction(pun_acts, nonpun_acts, direction, mean_pun, mean_nonpun, layer_name):\n",
    "    \"\"\"\n",
    "    PCA plot with the pun direction visualized as an arrow.\n",
    "    \"\"\"\n",
    "    # Combine for joint PCA\n",
    "    all_acts = np.vstack([pun_acts, nonpun_acts])\n",
    "    \n",
    "    # Fit PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    projected = pca.fit_transform(all_acts)\n",
    "    \n",
    "    # Split back\n",
    "    pun_proj = projected[:len(pun_acts)]\n",
    "    nonpun_proj = projected[len(pun_acts):]\n",
    "    \n",
    "    # Project means and direction\n",
    "    mean_pun_proj = pca.transform(mean_pun.reshape(1, -1))[0]\n",
    "    mean_nonpun_proj = pca.transform(mean_nonpun.reshape(1, -1))[0]\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    ax.scatter(pun_proj[:, 0], pun_proj[:, 1], c='coral', label='Puns', \n",
    "               alpha=0.6, s=100, edgecolors='darkred', linewidth=0.5)\n",
    "    ax.scatter(nonpun_proj[:, 0], nonpun_proj[:, 1], c='steelblue', label='Non-puns',\n",
    "               alpha=0.6, s=100, edgecolors='darkblue', linewidth=0.5)\n",
    "    \n",
    "    # Plot means\n",
    "    ax.scatter([mean_pun_proj[0]], [mean_pun_proj[1]], c='red', s=300, \n",
    "               marker='*', edgecolors='black', linewidth=2, label='Pun mean', zorder=5)\n",
    "    ax.scatter([mean_nonpun_proj[0]], [mean_nonpun_proj[1]], c='blue', s=300,\n",
    "               marker='*', edgecolors='black', linewidth=2, label='Non-pun mean', zorder=5)\n",
    "    \n",
    "    # Draw arrow from non-pun mean to pun mean (the pun direction)\n",
    "    arrow_dx = mean_pun_proj[0] - mean_nonpun_proj[0]\n",
    "    arrow_dy = mean_pun_proj[1] - mean_nonpun_proj[1]\n",
    "    ax.annotate('', xy=(mean_pun_proj[0], mean_pun_proj[1]),\n",
    "                xytext=(mean_nonpun_proj[0], mean_nonpun_proj[1]),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=3))\n",
    "    \n",
    "    # Label the arrow\n",
    "    mid_x = (mean_pun_proj[0] + mean_nonpun_proj[0]) / 2\n",
    "    mid_y = (mean_pun_proj[1] + mean_nonpun_proj[1]) / 2\n",
    "    ax.annotate('Pun Direction', xy=(mid_x, mid_y), fontsize=12, \n",
    "                color='darkgreen', fontweight='bold',\n",
    "                xytext=(10, 10), textcoords='offset points')\n",
    "    \n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "    ax.set_title(f'{layer_name}: PCA with Pun Direction')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for the best layer (based on separability)\n",
    "best_layer = max(separability_results.keys(), \n",
    "                 key=lambda k: separability_results[k]['test_accuracy'])\n",
    "print(f\"Best layer for visualization: {best_layer}\")\n",
    "\n",
    "plot_with_direction(\n",
    "    pun_activations[best_layer],\n",
    "    nonpun_activations[best_layer],\n",
    "    pun_directions[best_layer]['direction'],\n",
    "    pun_directions[best_layer]['mean_pun'],\n",
    "    pun_directions[best_layer]['mean_nonpun'],\n",
    "    best_layer.capitalize()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Part 7: Generalization Test\n",
    "\n",
    "The key test from Geometry of Truth: does the pun direction generalize to new, unseen puns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Held-out test examples (not used for computing the direction)\n",
    "test_puns = [\n",
    "    \"Why do programmers prefer dark mode? Because light attracts bugs.\",\n",
    "    \"What do you call a lazy kangaroo? A pouch potato.\",\n",
    "    \"Why did the stadium get hot? All the fans left.\",\n",
    "]\n",
    "\n",
    "test_nonpuns = [\n",
    "    \"Why do programmers use version control? To track code changes.\",\n",
    "    \"What do you call a baby kangaroo? A joey.\",\n",
    "    \"Why did the stadium close? For maintenance.\",\n",
    "]\n",
    "\n",
    "# Get activations for test examples at the best layer\n",
    "best_layer_idx = layers_to_examine[best_layer]\n",
    "\n",
    "print(f\"Testing generalization at {best_layer} layer (L{best_layer_idx})...\\n\")\n",
    "\n",
    "test_pun_acts = collect_activations(test_puns, model, best_layer_idx, remote=REMOTE)\n",
    "test_nonpun_acts = collect_activations(test_nonpuns, model, best_layer_idx, remote=REMOTE)\n",
    "\n",
    "# Score on pun direction\n",
    "direction = pun_directions[best_layer]['direction']\n",
    "\n",
    "print(\"\\nTest pun scores (should be positive):\")\n",
    "for pun, score in zip(test_puns, score_on_direction(test_pun_acts, direction)):\n",
    "    print(f\"  {score:+.3f}: {pun[:50]}...\")\n",
    "\n",
    "print(\"\\nTest non-pun scores (should be negative):\")\n",
    "for nonpun, score in zip(test_nonpuns, score_on_direction(test_nonpun_acts, direction)):\n",
    "    print(f\"  {score:+.3f}: {nonpun[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Exercise 1: Position Analysis\n",
    "\n",
    "We've been using the final token position. How does the representation change at different positions (e.g., middle of punchline, end of setup)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare activations at different positions\n",
    "# 1. Final token (current approach)\n",
    "# 2. Middle of the sentence\n",
    "# 3. End of the setup (before punchline)\n",
    "#\n",
    "# Question: At which position is the pun/non-pun distinction clearest?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Exercise 2: Fine-Grained Layer Analysis\n",
    "\n",
    "We sampled only 4 layers. Create a heatmap of linear separability across all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create heatmap of separability vs layer\n",
    "# For each layer (or every 4th layer):\n",
    "#   1. Collect activations\n",
    "#   2. Train logistic regression\n",
    "#   3. Record test accuracy\n",
    "# Plot: x-axis = layer, y-axis = accuracy\n",
    "#\n",
    "# Question: At which layer does pun understanding \"emerge\"?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Exercise 3: Pun Subtypes\n",
    "\n",
    "Are different types of puns (homograph, homophone, compound) represented differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Label puns by type and visualize separately\n",
    "# Categories:\n",
    "#   - Homograph: same spelling, different meanings (current, interest)\n",
    "#   - Homophone: same sound, different spellings (knight/night)\n",
    "#   - Compound: play on phrases (time flies)\n",
    "#\n",
    "# Question: Do different pun types cluster together or separately?\n",
    "# Do they have different \"directions\"?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Exercise 4: 3D Visualization\n",
    "\n",
    "Create an interactive 3D PCA plot to see more structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create 3D PCA visualization\n",
    "# Use plotly for interactive 3D scatter:\n",
    "#   pip install plotly\n",
    "#   import plotly.express as px\n",
    "#\n",
    "# This can reveal structure hidden in 2D projections\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we applied the \"Geometry of Truth\" methodology to puns:\n",
    "\n",
    "1. **PCA Visualization:** Revealed whether puns and non-puns cluster separately at different layers\n",
    "\n",
    "2. **Pun Direction:** Computed a linear direction that captures \"pun-ness\" using mass mean-difference\n",
    "\n",
    "3. **Classification:** Tested how well the pun direction separates puns from non-puns\n",
    "\n",
    "4. **Generalization:** Verified the direction works on held-out examples\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- Puns form a (partially) linearly separable cluster in activation space\n",
    "- The separation typically improves in middle-to-late layers\n",
    "- A simple linear direction can classify puns with reasonable accuracy\n",
    "- The direction generalizes to new pun examples\n",
    "\n",
    "### Questions for Your Research\n",
    "\n",
    "- How does your concept compare to puns in terms of linear separability?\n",
    "- At which layer does your concept \"emerge\" in the representation?\n",
    "- Is your concept direction as generalizable as the truth direction from Marks & Tegmark?\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Apply this methodology to your research concept\n",
    "2. Compare geometric structure with causal importance (Week 5)\n",
    "3. Use the concept direction for steering experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
