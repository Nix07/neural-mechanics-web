{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Steering with SAE Features via NDIF\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nix07/neural-mechanics-web/blob/main/labs/week2/sae_steering_ndif.ipynb)\n",
    "\n",
    "This notebook demonstrates **activation steering** using Sparse Autoencoder (SAE) features on large models via NDIF.\n",
    "\n",
    "**Key Idea:** SAE decoder vectors represent interpretable \"directions\" in activation space. By adding these vectors to model activations during generation, we can steer model behavior toward specific concepts.\n",
    "\n",
    "## What We'll Do\n",
    "1. Load pretrained SAE weights from HuggingFace\n",
    "2. Find features related to humor/puns using Neuronpedia\n",
    "3. Extract decoder vectors for those features\n",
    "4. Use nnsight/NDIF to steer generation on large models\n",
    "\n",
    "## References\n",
    "- [SAE Lens](https://github.com/jbloomAus/SAELens) - Library for training and loading SAEs\n",
    "- [Neuronpedia](https://www.neuronpedia.org/) - Platform for exploring SAE features\n",
    "- [Steering Using SAE Features](https://docs.neuronpedia.org/steering) - Neuronpedia steering docs\n",
    "- [nnsight](https://nnsight.net/) - Neural network inspection library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nnsight sae-lens requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport requests\nimport json\nfrom nnsight import LanguageModel, CONFIG\nfrom sae_lens import SAE\n\n# Configure NDIF API key from Colab secrets\ntry:\n    from google.colab import userdata\n    CONFIG.set_default_api_key(userdata.get('NDIF_API'))\nexcept:\n    pass  # Not in Colab or secret not set\n\n# Use NDIF for remote execution on large models\nREMOTE = True\n\n# For local testing, set REMOTE = False\nif REMOTE:\n    MODEL_ID = \"google/gemma-2-2b\"\nelse:\n    MODEL_ID = \"gpt2\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = LanguageModel(MODEL_ID, device_map=\"auto\")\n",
    "\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"Layers: {model.config.num_hidden_layers}\")\n",
    "print(f\"Hidden size: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Part 1: Load Pretrained SAE from HuggingFace\n",
    "\n",
    "SAE Lens provides pretrained SAEs for many models. Each SAE has:\n",
    "- **Encoder**: Maps activations to sparse feature activations\n",
    "- **Decoder**: Maps feature activations back to residual stream (these are our steering vectors!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained SAE for Gemma-2-2B\n",
    "# See: https://github.com/jbloomAus/SAELens/blob/main/sae_lens/pretrained_saes.yaml\n",
    "\n",
    "# For Gemma-2-2B, we use the gemma-scope SAEs\n",
    "# Format: \"gemma-scope-2b-pt-res\" for residual stream SAEs\n",
    "\n",
    "if \"gemma\" in MODEL_ID.lower():\n",
    "    SAE_RELEASE = \"gemma-scope-2b-pt-res\"\n",
    "    SAE_ID = \"layer_12/width_16k/average_l0_71\"  # Layer 12, 16k features\n",
    "    TARGET_LAYER = 12\n",
    "elif \"gpt2\" in MODEL_ID.lower():\n",
    "    SAE_RELEASE = \"gpt2-small-res-jb\"\n",
    "    SAE_ID = \"blocks.6.hook_resid_pre\"\n",
    "    TARGET_LAYER = 6\n",
    "else:\n",
    "    raise ValueError(f\"No pretrained SAE configured for {MODEL_ID}\")\n",
    "\n",
    "print(f\"Loading SAE: {SAE_RELEASE} / {SAE_ID}\")\n",
    "\n",
    "# Load the SAE\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=SAE_RELEASE,\n",
    "    sae_id=SAE_ID,\n",
    "    device=\"cpu\"  # Load to CPU, we'll send vectors to NDIF\n",
    ")\n",
    "\n",
    "print(f\"SAE loaded!\")\n",
    "print(f\"  Features: {sae.cfg.d_sae}\")\n",
    "print(f\"  Hidden dim: {sae.cfg.d_in}\")\n",
    "print(f\"  Decoder shape: {sae.W_dec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Part 2: Find Interesting Features via Neuronpedia\n",
    "\n",
    "Neuronpedia catalogs SAE features with automated explanations. Let's search for features related to humor, jokes, and puns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuronpedia API helper functions\n",
    "NP_API_BASE = \"https://www.neuronpedia.org/api\"\n",
    "\n",
    "def search_features(query, model_id=\"gemma-2-2b\", limit=10):\n",
    "    \"\"\"Search Neuronpedia for features matching a query.\"\"\"\n",
    "    url = f\"{NP_API_BASE}/search\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"modelId\": model_id,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def get_feature_info(model_id, source, index):\n",
    "    \"\"\"Get detailed info about a specific feature.\"\"\"\n",
    "    url = f\"{NP_API_BASE}/feature/{model_id}/{source}/{index}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "    except:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for humor-related features\n",
    "search_terms = [\"humor\", \"joke\", \"funny\", \"pun\", \"wordplay\", \"comedy\"]\n",
    "\n",
    "found_features = []\n",
    "np_model_id = \"gemma-2-2b\" if \"gemma\" in MODEL_ID else \"gpt2-small\"\n",
    "\n",
    "print(\"Searching Neuronpedia for humor-related features...\\n\")\n",
    "\n",
    "for term in search_terms:\n",
    "    results = search_features(term, model_id=np_model_id, limit=3)\n",
    "    if results:\n",
    "        print(f\"'{term}':\")\n",
    "        for f in results:\n",
    "            source = f.get('source', '')\n",
    "            index = f.get('index', '')\n",
    "            expl = f.get('explanation', '')[:60]\n",
    "            print(f\"  {source}/{index}: {expl}\")\n",
    "            found_features.append({\n",
    "                'source': source,\n",
    "                'index': index,\n",
    "                'explanation': f.get('explanation', ''),\n",
    "                'term': term\n",
    "            })\n",
    "    else:\n",
    "        print(f\"'{term}': No results\")\n",
    "\n",
    "print(f\"\\nFound {len(found_features)} potentially relevant features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Part 3: Extract Steering Vectors\n",
    "\n",
    "Each SAE feature has a corresponding decoder vector. This vector represents the \"direction\" in activation space that the feature encodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_vector(sae, feature_idx):\n",
    "    \"\"\"\n",
    "    Extract the steering vector for a specific feature.\n",
    "    \n",
    "    The decoder weight W_dec[feature_idx] is the direction in \n",
    "    activation space that this feature represents.\n",
    "    \"\"\"\n",
    "    # W_dec shape: (d_sae, d_in) - each row is a feature's decoder vector\n",
    "    steering_vector = sae.W_dec[feature_idx].detach().clone()\n",
    "    return steering_vector\n",
    "\n",
    "# Example: Get steering vector for a specific feature\n",
    "# You can change this to any feature index you want to explore\n",
    "EXAMPLE_FEATURE_IDX = 1000  # Change this based on Neuronpedia search\n",
    "\n",
    "steering_vec = get_steering_vector(sae, EXAMPLE_FEATURE_IDX)\n",
    "print(f\"Steering vector for feature {EXAMPLE_FEATURE_IDX}:\")\n",
    "print(f\"  Shape: {steering_vec.shape}\")\n",
    "print(f\"  Norm: {steering_vec.norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined steering vector from multiple features\n",
    "def create_combined_steering_vector(sae, feature_indices, weights=None):\n",
    "    \"\"\"\n",
    "    Combine multiple feature vectors into a single steering direction.\n",
    "    \n",
    "    Args:\n",
    "        sae: The loaded SAE\n",
    "        feature_indices: List of feature indices to combine\n",
    "        weights: Optional weights for each feature (default: equal)\n",
    "        \n",
    "    Returns:\n",
    "        Combined steering vector\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0] * len(feature_indices)\n",
    "    \n",
    "    combined = torch.zeros(sae.cfg.d_in)\n",
    "    for idx, weight in zip(feature_indices, weights):\n",
    "        combined += weight * sae.W_dec[idx]\n",
    "    \n",
    "    # Normalize to unit length\n",
    "    combined = combined / combined.norm()\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Example: Combine features related to humor\n",
    "# Replace these with actual feature indices from Neuronpedia\n",
    "HUMOR_FEATURES = [1000, 2000, 3000]  # Placeholder - replace with real indices\n",
    "\n",
    "humor_steering = create_combined_steering_vector(sae, HUMOR_FEATURES)\n",
    "print(f\"Combined humor steering vector:\")\n",
    "print(f\"  Shape: {humor_steering.shape}\")\n",
    "print(f\"  Norm: {humor_steering.norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Part 4: Steering Generation via NDIF\n",
    "\n",
    "Now we use nnsight to add our steering vector to the model's activations during generation. This nudges the model toward generating content related to our target concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAESteeringGenerator:\n",
    "    \"\"\"\n",
    "    Generate text with SAE-based steering via NDIF.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, steering_vector, target_layer, strength=1.0):\n",
    "        self.model = model\n",
    "        self.steering_vector = steering_vector\n",
    "        self.target_layer = target_layer\n",
    "        self.strength = strength\n",
    "    \n",
    "    def generate(self, prompt, max_new_tokens=50, remote=True):\n",
    "        \"\"\"\n",
    "        Generate text with steering applied.\n",
    "        \n",
    "        The steering vector is added to the residual stream at the target layer\n",
    "        for all generated tokens.\n",
    "        \"\"\"\n",
    "        tokens = self.model.tokenizer.encode(prompt)\n",
    "        generated = list(tokens)\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            input_ids = torch.tensor([generated])\n",
    "            \n",
    "            with self.model.trace(remote=remote) as tracer:\n",
    "                with tracer.invoke(input_ids):\n",
    "                    # Get the residual stream at target layer\n",
    "                    resid = self.model.model.layers[self.target_layer].output[0]\n",
    "                    \n",
    "                    # Add steering vector to all positions\n",
    "                    steering = self.steering_vector.to(resid.device)\n",
    "                    resid[:, :, :] = resid + self.strength * steering\n",
    "                    \n",
    "                    # Get output logits\n",
    "                    logits = self.model.output.logits.save()\n",
    "            \n",
    "            # Sample next token\n",
    "            next_logits = logits.value[0, -1, :]\n",
    "            next_token = torch.argmax(next_logits).item()\n",
    "            \n",
    "            if next_token == self.model.tokenizer.eos_token_id:\n",
    "                break\n",
    "            \n",
    "            generated.append(next_token)\n",
    "        \n",
    "        return self.model.tokenizer.decode(generated)\n",
    "    \n",
    "    def generate_unsteered(self, prompt, max_new_tokens=50, remote=True):\n",
    "        \"\"\"\n",
    "        Generate text WITHOUT steering for comparison.\n",
    "        \"\"\"\n",
    "        tokens = self.model.tokenizer.encode(prompt)\n",
    "        generated = list(tokens)\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            input_ids = torch.tensor([generated])\n",
    "            \n",
    "            with self.model.trace(remote=remote) as tracer:\n",
    "                with tracer.invoke(input_ids):\n",
    "                    logits = self.model.output.logits.save()\n",
    "            \n",
    "            next_logits = logits.value[0, -1, :]\n",
    "            next_token = torch.argmax(next_logits).item()\n",
    "            \n",
    "            if next_token == self.model.tokenizer.eos_token_id:\n",
    "                break\n",
    "            \n",
    "            generated.append(next_token)\n",
    "        \n",
    "        return self.model.tokenizer.decode(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a steered generator\n",
    "# Use a single feature's decoder vector as the steering direction\n",
    "\n",
    "# Get a steering vector (replace with a real humor-related feature index)\n",
    "STEERING_FEATURE = 5000  # Placeholder - find a real humor feature on Neuronpedia\n",
    "steering_vec = get_steering_vector(sae, STEERING_FEATURE)\n",
    "\n",
    "generator = SAESteeringGenerator(\n",
    "    model=model,\n",
    "    steering_vector=steering_vec,\n",
    "    target_layer=TARGET_LAYER,\n",
    "    strength=2.0  # Adjust strength to control effect\n",
    ")\n",
    "\n",
    "print(f\"Generator created with:\")\n",
    "print(f\"  Feature: {STEERING_FEATURE}\")\n",
    "print(f\"  Layer: {TARGET_LAYER}\")\n",
    "print(f\"  Strength: {generator.strength}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare steered vs unsteered generation\n",
    "test_prompts = [\n",
    "    \"Why do programmers prefer\",\n",
    "    \"The scientist walked into the lab and\",\n",
    "    \"My favorite thing about cooking is\",\n",
    "]\n",
    "\n",
    "print(\"Comparing steered vs unsteered generation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    unsteered = generator.generate_unsteered(prompt, max_new_tokens=30, remote=REMOTE)\n",
    "    print(f\"\\nUnsteered: {unsteered}\")\n",
    "    \n",
    "    steered = generator.generate(prompt, max_new_tokens=30, remote=REMOTE)\n",
    "    print(f\"\\nSteered:   {steered}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Part 5: Exploring Steering Strength\n",
    "\n",
    "The strength parameter controls how strongly we push the model toward the target concept. Let's explore different strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different steering strengths\n",
    "prompt = \"Why do electricians make good\"\n",
    "strengths = [0.0, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for strength in strengths:\n",
    "    generator.strength = strength\n",
    "    output = generator.generate(prompt, max_new_tokens=30, remote=REMOTE)\n",
    "    print(f\"\\nStrength {strength:4.1f}: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Part 6: Positive vs Negative Steering\n",
    "\n",
    "We can steer TOWARD a concept (positive) or AWAY from it (negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare positive and negative steering\n",
    "prompt = \"The comedian walked on stage and said\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for strength in [-3.0, 0.0, 3.0]:\n",
    "    generator.strength = strength\n",
    "    output = generator.generate(prompt, max_new_tokens=40, remote=REMOTE)\n",
    "    \n",
    "    label = \"NEGATIVE\" if strength < 0 else (\"NEUTRAL\" if strength == 0 else \"POSITIVE\")\n",
    "    print(f\"\\n{label} ({strength:+.1f}): {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Exercise 1: Find Your Own Steering Features\n",
    "\n",
    "Use Neuronpedia to find features related to a concept you're interested in, then test steering with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Search for features related to your concept\n",
    "# my_concept = \"sarcasm\"  # or \"poetry\", \"science\", etc.\n",
    "# results = search_features(my_concept, model_id=np_model_id)\n",
    "\n",
    "# TODO: Create a steering vector from those features\n",
    "# my_features = [...]  # feature indices from Neuronpedia\n",
    "# my_steering = create_combined_steering_vector(sae, my_features)\n",
    "\n",
    "# TODO: Test generation with your steering vector\n",
    "# my_generator = SAESteeringGenerator(model, my_steering, TARGET_LAYER, strength=2.0)\n",
    "# output = my_generator.generate(\"Your prompt here\", remote=REMOTE)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Exercise 2: Layer-Wise Steering\n",
    "\n",
    "Different layers may have different effects when steered. Try steering at different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test steering at different layers\n",
    "# Note: You'll need to load SAEs for different layers\n",
    "# layers_to_test = [4, 8, 12, 16, 20]\n",
    "\n",
    "# Question: Does steering at earlier vs later layers have different effects?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Exercise 3: Contrastive Steering\n",
    "\n",
    "Combine positive and negative features to create more precise steering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a contrastive steering vector\n",
    "# Example: \"humor\" - \"serious\" to get pure humor without formality\n",
    "\n",
    "# humor_features = [...]\n",
    "# serious_features = [...]\n",
    "\n",
    "# contrastive = (sum of humor decoder vecs) - (sum of serious decoder vecs)\n",
    "# contrastive = contrastive / contrastive.norm()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "\n",
    "1. **SAE decoder vectors** are interpretable directions in activation space\n",
    "\n",
    "2. **Neuronpedia** catalogs features with explanations, helping us find relevant features\n",
    "\n",
    "3. **Steering via NDIF** lets us modify large model behavior without fine-tuning\n",
    "\n",
    "4. **Strength parameter** controls how strongly we push toward the concept\n",
    "\n",
    "5. **Positive/negative steering** lets us amplify or suppress concepts\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- SAE features provide a \"vocabulary\" for describing model behavior\n",
    "- Steering is fast (no training) but approximate (may have side effects)\n",
    "- Combining multiple features can create more specific effects\n",
    "- Layer choice matters: early layers affect more, late layers are more specific\n",
    "\n",
    "### Connections to Course Themes\n",
    "\n",
    "| Week | Method | Connection |\n",
    "|------|--------|-----------|\n",
    "| 1 | Logit Lens | SAE features explain what logit lens shows |\n",
    "| 4 | Geometry | Decoder vectors ARE the geometric directions |\n",
    "| 5 | Causation | Steering is a form of causal intervention |\n",
    "| 6 | Probes | Compare: probe direction vs SAE decoder |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Explore more features on [Neuronpedia](https://www.neuronpedia.org/)\n",
    "2. Try steering for your project's concept\n",
    "3. Compare SAE steering with mass-mean-difference steering (Week 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}