{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Exploring SAE Features with Neuronpedia\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nix07/neural-mechanics-web/blob/main/labs/week2/neuronpedia_explorer.ipynb)\n\nThis notebook demonstrates how to explore **Sparse Autoencoder (SAE) features** using [Neuronpedia](https://www.neuronpedia.org/), an open-source platform for interpretability research.\n\n**Key Idea:** SAEs decompose model activations into interpretable features. Neuronpedia catalogs millions of these features with automated explanations and example activations, letting us explore what concepts a model has learned.\n\nWe'll use **GPT-2 Small** to explore how SAE features activate on **puns**â€”looking for features that might encode humor, wordplay, or dual meanings.\n\n## References\n- [Neuronpedia](https://www.neuronpedia.org/)\n- [Neuronpedia Documentation](https://docs.neuronpedia.org/)\n- [Sparse Autoencoders paper](https://arxiv.org/abs/2309.08600)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the Neuronpedia Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q neuronpedia requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "# Base URL for Neuronpedia API\n",
    "NP_API_BASE = \"https://www.neuronpedia.org/api\"\n",
    "\n",
    "# We'll use GPT OSS 20B (also known as \"gpt-neox-20b\" in some contexts)\n",
    "# Check Neuronpedia for available models and SAE sources\n",
    "MODEL_ID = \"EleutherAI/gpt-neox-20b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Neuronpedia's Feature System\n",
    "\n",
    "Every SAE feature on Neuronpedia has a unique identifier with three parts:\n",
    "\n",
    "1. **Model ID**: e.g., `gpt2-small`, `gemma-2-2b`\n",
    "2. **Source**: Layer number + SAE info, e.g., `6-res-jb` (Layer 6, residual stream, Joseph Bloom)\n",
    "3. **Index**: The feature number within that SAE\n",
    "\n",
    "Let's explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(model_id, source, index):\n",
    "    \"\"\"Fetch a specific SAE feature from Neuronpedia.\"\"\"\n",
    "    url = f\"{NP_API_BASE}/feature/{model_id}/{source}/{index}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def display_feature(feature_data):\n",
    "    \"\"\"Display feature information nicely.\"\"\"\n",
    "    if not feature_data:\n",
    "        return\n",
    "    \n",
    "    print(f\"Feature: {feature_data.get('modelId')}/{feature_data.get('source')}/{feature_data.get('index')}\")\n",
    "    print(f\"\\nExplanation: {feature_data.get('explanation', 'No explanation available')}\")\n",
    "    \n",
    "    # Show top activating examples if available\n",
    "    activations = feature_data.get('activations', [])\n",
    "    if activations:\n",
    "        print(f\"\\nTop activating examples ({len(activations)} total):\")\n",
    "        for i, act in enumerate(activations[:5]):\n",
    "            tokens = act.get('tokens', [])\n",
    "            values = act.get('values', [])\n",
    "            # Reconstruct the text\n",
    "            text = ''.join(tokens)\n",
    "            print(f\"  {i+1}. {text[:100]}...\" if len(text) > 100 else f\"  {i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Features on GPT-2 Small (Demo)\n",
    "\n",
    "Let's start with GPT-2 Small which has well-documented SAE features. We'll then apply what we learn to larger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Look up a known interesting feature\n",
    "# This is feature 650 from layer 6 residual stream SAE on GPT-2 Small\n",
    "feature = get_feature(\"gpt2-small\", \"6-res_scefr-ajt\", \"650\")\n",
    "display_feature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Humor/Pun-Related Features\n",
    "\n",
    "Neuronpedia provides search functionality. Let's look for features that might relate to humor, jokes, or wordplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_features(query, model_id=\"gpt2-small\", limit=10):\n",
    "    \"\"\"Search for features by explanation text.\"\"\"\n",
    "    url = f\"{NP_API_BASE}/search\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"modelId\": model_id,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Search failed: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Search for features related to humor/jokes\n",
    "humor_features = search_features(\"joke\", limit=5)\n",
    "print(\"Features related to 'joke':\")\n",
    "for f in humor_features:\n",
    "    print(f\"  - {f.get('source')}/{f.get('index')}: {f.get('explanation', 'No explanation')[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for features that might capture wordplay\n",
    "wordplay_terms = [\"pun\", \"double meaning\", \"humor\", \"funny\", \"joke\"]\n",
    "\n",
    "for term in wordplay_terms:\n",
    "    results = search_features(term, limit=3)\n",
    "    print(f\"\\n'{term}' features:\")\n",
    "    if results:\n",
    "        for f in results:\n",
    "            print(f\"  {f.get('source')}/{f.get('index')}: {f.get('explanation', '')[:60]}\")\n",
    "    else:\n",
    "        print(\"  No results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Feature Exploration\n",
    "\n",
    "The best way to explore features is through Neuronpedia's web interface. Let's create links to explore specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuronpedia_url(model_id, source, index):\n",
    "    \"\"\"Generate a Neuronpedia URL for a feature.\"\"\"\n",
    "    return f\"https://www.neuronpedia.org/{model_id}/{source}/{index}\"\n",
    "\n",
    "def display_feature_link(model_id, source, index, description=\"\"):\n",
    "    \"\"\"Display a clickable link to a feature.\"\"\"\n",
    "    url = neuronpedia_url(model_id, source, index)\n",
    "    display(HTML(f'<a href=\"{url}\" target=\"_blank\">{model_id}/{source}/{index}</a>: {description}'))\n",
    "\n",
    "# Some interesting features to explore\n",
    "print(\"Explore these features on Neuronpedia:\")\n",
    "display_feature_link(\"gpt2-small\", \"6-res_scefr-ajt\", \"650\", \"Example feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Features that Activate on Puns\n",
    "\n",
    "Let's use Neuronpedia's inference API to find which SAE features activate most strongly on pun-containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This requires the neuronpedia_inference_client package\n",
    "# !pip install neuronpedia_inference_client\n",
    "\n",
    "# For now, let's manually look at what features might activate on puns\n",
    "# by examining the Neuronpedia web interface\n",
    "\n",
    "pun_examples = [\n",
    "    \"Why do electricians make good swimmers? Because they know the current.\",\n",
    "    \"Why did the banker break up with his girlfriend? He lost interest.\",\n",
    "    \"Time flies like an arrow; fruit flies like a banana.\",\n",
    "    \"I used to be a banker, but I lost interest.\",\n",
    "]\n",
    "\n",
    "print(\"Pun examples to explore on Neuronpedia:\")\n",
    "for pun in pun_examples:\n",
    "    print(f\"  - {pun}\")\n",
    "\n",
    "print(\"\\nTo find activating features:\")\n",
    "print(\"1. Go to https://www.neuronpedia.org/gpt2-small\")\n",
    "print(\"2. Use the 'Test Prompt' feature to enter these puns\")\n",
    "print(\"3. See which features light up on the pun words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Explore Feature Families\n",
    "\n",
    "Some features form \"families\" that capture related concepts. Can you find features that capture:\n",
    "- Electricity-related words\n",
    "- Water/swimming words  \n",
    "- Question words (\"why\", \"what\", \"how\")\n",
    "\n",
    "These might all activate together in our electrician pun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Search for features in these categories\n",
    "categories = [\"electricity\", \"water\", \"swimming\", \"question\"]\n",
    "\n",
    "for cat in categories:\n",
    "    print(f\"\\n=== {cat.upper()} ===\")\n",
    "    results = search_features(cat, model_id=\"gpt2-small\", limit=5)\n",
    "    for f in results:\n",
    "        source = f.get('source', '')\n",
    "        index = f.get('index', '')\n",
    "        expl = f.get('explanation', '')[:60]\n",
    "        print(f\"  {source}/{index}: {expl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Compare Pun vs Literal Contexts\n",
    "\n",
    "The word \"current\" appears in both pun and literal contexts. Do the same features activate in both cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contexts to compare:\n",
    "pun_context = \"Why do electricians make good swimmers? Because they know the current.\"\n",
    "literal_electrical = \"The electrical current flows through the wire at high voltage.\"\n",
    "literal_water = \"The river current was too strong for the small boat.\"\n",
    "\n",
    "print(\"Compare these contexts on Neuronpedia:\")\n",
    "print(f\"\\n1. PUN: {pun_context}\")\n",
    "print(f\"\\n2. ELECTRICAL: {literal_electrical}\")\n",
    "print(f\"\\n3. WATER: {literal_water}\")\n",
    "print(\"\\nQuestion: Which features activate on 'current' in each context?\")\n",
    "print(\"Are there features unique to the pun context?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Steering with Features\n",
    "\n",
    "Neuronpedia supports \"steering\" - boosting or suppressing specific features to change model behavior. Can we make a model more likely to generate puns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steering requires an API key\n",
    "# Sign up at neuronpedia.org and get your key from neuronpedia.org/account\n",
    "\n",
    "# Example steering code (requires API key):\n",
    "\"\"\"\n",
    "import os\n",
    "from neuronpedia.np_vector import NPVector\n",
    "\n",
    "os.environ[\"NEURONPEDIA_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "# Create a steering vector from features associated with humor\n",
    "# This would boost those features during generation\n",
    "\n",
    "response = np_vector.steer_chat(\n",
    "    steered_chat_messages=[{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Why do electricians make good swimmers?\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\"\"\"\n",
    "\n",
    "print(\"To try steering:\")\n",
    "print(\"1. Get an API key from neuronpedia.org/account\")\n",
    "print(\"2. Find features that activate on jokes/puns\")\n",
    "print(\"3. Use NPVector to boost those features during generation\")\n",
    "print(\"4. See if the model generates more puns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Larger Models\n",
    "\n",
    "GPT-2 Small is great for learning, but larger models often have more interpretable features. Let's explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available models on Neuronpedia (check website for current list)\n",
    "models_to_explore = [\n",
    "    \"gpt2-small\",\n",
    "    \"gpt2-medium\", \n",
    "    \"gpt2-large\",\n",
    "    \"gemma-2-2b\",\n",
    "    \"gemma-2-9b\",\n",
    "    # GPT OSS / EleutherAI models may have different IDs\n",
    "]\n",
    "\n",
    "print(\"Models available on Neuronpedia:\")\n",
    "for m in models_to_explore:\n",
    "    url = f\"https://www.neuronpedia.org/{m}\"\n",
    "    print(f\"  - {m}: {url}\")\n",
    "\n",
    "print(\"\\nNote: Check neuronpedia.org for the most current list of models and SAEs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "\n",
    "1. **SAE Features** decompose model activations into (hopefully) interpretable units\n",
    "\n",
    "2. **Neuronpedia** catalogs millions of features with automated explanations and examples\n",
    "\n",
    "3. **Feature Search** helps find features related to specific concepts like humor or wordplay\n",
    "\n",
    "4. **Puns are challenging** because they require understanding that a word activates multiple meaning-related features simultaneously\n",
    "\n",
    "### Questions to Consider\n",
    "\n",
    "- Do puns activate \"humor\" features, or just multiple literal-meaning features?\n",
    "- Can you find features that specifically capture ambiguity or double meanings?\n",
    "- How do feature activations differ between pun and literal uses of the same word?\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Explore the Neuronpedia web interface for hands-on feature browsing\n",
    "2. Use the inference client to find features on your own text\n",
    "3. Try steering to see if boosting \"humor\" features changes model behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}